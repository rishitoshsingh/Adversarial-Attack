{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(10, 784, requires_grad = False)\n",
    "x = torch.randn(784, 1, requires_grad = True)\n",
    "b = torch.randn(10, 1,  requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,learning_rate,_lambda,x_target,y_goal):\n",
    "    w = Variable(torch.randn(10, 784), requires_grad = False)\n",
    "    x = Variable(torch.randn(784, 1), requires_grad = True)\n",
    "    b = Variable(torch.randn(10, 1),  requires_grad = False)\n",
    "#     plt.imshow(x.reshape((28,28)))\n",
    "    for epoch in range(epochs):\n",
    "        v = torch.mm(w,x) + b\n",
    "        y = torch.nn.Sigmoid()(v)\n",
    "        c = (1/2) * torch.sum((y_goal-y)**2) + _lambda * torch.sum((x - x_target)**2)\n",
    "        print(\"Epoch {} : Loss {}\".format(epoch,c))\n",
    "        c.backward()\n",
    "        x.data = x.data - (learning_rate * x.grad)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss 1.4389499425888062\n",
      "Epoch 1 : Loss 1.4365016222000122\n",
      "Epoch 2 : Loss 1.4312471151351929\n",
      "Epoch 3 : Loss 1.4223719835281372\n",
      "Epoch 4 : Loss 1.408388376235962\n",
      "Epoch 5 : Loss 1.3867383003234863\n",
      "Epoch 6 : Loss 1.3532291650772095\n",
      "Epoch 7 : Loss 1.3018430471420288\n",
      "Epoch 8 : Loss 1.2274514436721802\n",
      "Epoch 9 : Loss 1.1368229389190674\n",
      "Epoch 10 : Loss 1.0591375827789307\n",
      "Epoch 11 : Loss 1.0181922912597656\n",
      "Epoch 12 : Loss 1.0044074058532715\n",
      "Epoch 13 : Loss 1.0009411573410034\n",
      "Epoch 14 : Loss 1.000192642211914\n",
      "Epoch 15 : Loss 1.0000418424606323\n",
      "Epoch 16 : Loss 1.0000125169754028\n",
      "Epoch 17 : Loss 1.0000066757202148\n",
      "Epoch 18 : Loss 1.0000053644180298\n",
      "Epoch 19 : Loss 1.0000048875808716\n",
      "Epoch 20 : Loss 1.0000048875808716\n",
      "Epoch 21 : Loss 1.000004529953003\n",
      "Epoch 22 : Loss 1.0000044107437134\n",
      "Epoch 23 : Loss 1.0000044107437134\n",
      "Epoch 24 : Loss 1.0000041723251343\n",
      "Epoch 25 : Loss 1.0000040531158447\n",
      "Epoch 26 : Loss 1.0000039339065552\n",
      "Epoch 27 : Loss 1.000003695487976\n",
      "Epoch 28 : Loss 1.000003695487976\n",
      "Epoch 29 : Loss 1.000003457069397\n",
      "Epoch 30 : Loss 1.0000033378601074\n",
      "Epoch 31 : Loss 1.0000030994415283\n",
      "Epoch 32 : Loss 1.0000030994415283\n",
      "Epoch 33 : Loss 1.0000028610229492\n",
      "Epoch 34 : Loss 1.0000028610229492\n",
      "Epoch 35 : Loss 1.0000026226043701\n",
      "Epoch 36 : Loss 1.0000025033950806\n",
      "Epoch 37 : Loss 1.0000022649765015\n",
      "Epoch 38 : Loss 1.000002145767212\n",
      "Epoch 39 : Loss 1.0000020265579224\n",
      "Epoch 40 : Loss 1.0000017881393433\n",
      "Epoch 41 : Loss 1.0000017881393433\n",
      "Epoch 42 : Loss 1.0000015497207642\n",
      "Epoch 43 : Loss 1.0000014305114746\n",
      "Epoch 44 : Loss 1.000001311302185\n",
      "Epoch 45 : Loss 1.000001072883606\n",
      "Epoch 46 : Loss 1.0000008344650269\n",
      "Epoch 47 : Loss 1.0000007152557373\n",
      "Epoch 48 : Loss 1.0000004768371582\n",
      "Epoch 49 : Loss 1.000000238418579\n",
      "Epoch 50 : Loss 1.0\n",
      "Epoch 51 : Loss 0.9999998807907104\n",
      "Epoch 52 : Loss 0.9999996423721313\n",
      "Epoch 53 : Loss 0.999999463558197\n",
      "Epoch 54 : Loss 0.9999992251396179\n",
      "Epoch 55 : Loss 0.9999989867210388\n",
      "Epoch 56 : Loss 0.9999986290931702\n",
      "Epoch 57 : Loss 0.9999985098838806\n",
      "Epoch 58 : Loss 0.9999982714653015\n",
      "Epoch 59 : Loss 0.9999979734420776\n",
      "Epoch 60 : Loss 0.9999977350234985\n",
      "Epoch 61 : Loss 0.9999973773956299\n",
      "Epoch 62 : Loss 0.999997079372406\n",
      "Epoch 63 : Loss 0.9999968409538269\n",
      "Epoch 64 : Loss 0.9999966025352478\n",
      "Epoch 65 : Loss 0.9999961853027344\n",
      "Epoch 66 : Loss 0.9999959468841553\n",
      "Epoch 67 : Loss 0.9999955892562866\n",
      "Epoch 68 : Loss 0.9999951720237732\n",
      "Epoch 69 : Loss 0.9999948143959045\n",
      "Epoch 70 : Loss 0.9999944567680359\n",
      "Epoch 71 : Loss 0.9999940395355225\n",
      "Epoch 72 : Loss 0.9999935626983643\n",
      "Epoch 73 : Loss 0.9999931454658508\n",
      "Epoch 74 : Loss 0.9999927878379822\n",
      "Epoch 75 : Loss 0.999992311000824\n",
      "Epoch 76 : Loss 0.9999918937683105\n",
      "Epoch 77 : Loss 0.9999914169311523\n",
      "Epoch 78 : Loss 0.9999909400939941\n",
      "Epoch 79 : Loss 0.9999904036521912\n",
      "Epoch 80 : Loss 0.999989926815033\n",
      "Epoch 81 : Loss 0.9999894499778748\n",
      "Epoch 82 : Loss 0.9999889135360718\n",
      "Epoch 83 : Loss 0.999988317489624\n",
      "Epoch 84 : Loss 0.9999878406524658\n",
      "Epoch 85 : Loss 0.9999871850013733\n",
      "Epoch 86 : Loss 0.9999865889549255\n",
      "Epoch 87 : Loss 0.9999858736991882\n",
      "Epoch 88 : Loss 0.9999852180480957\n",
      "Epoch 89 : Loss 0.999984622001648\n",
      "Epoch 90 : Loss 0.9999839067459106\n",
      "Epoch 91 : Loss 0.9999831318855286\n",
      "Epoch 92 : Loss 0.9999824166297913\n",
      "Epoch 93 : Loss 0.9999815821647644\n",
      "Epoch 94 : Loss 0.9999808073043823\n",
      "Epoch 95 : Loss 0.9999799728393555\n",
      "Epoch 96 : Loss 0.9999791383743286\n",
      "Epoch 97 : Loss 0.9999781250953674\n",
      "Epoch 98 : Loss 0.9999772906303406\n",
      "Epoch 99 : Loss 0.9999763369560242\n",
      "Epoch 100 : Loss 0.999975323677063\n",
      "Epoch 101 : Loss 0.999974250793457\n",
      "Epoch 102 : Loss 0.9999730587005615\n",
      "Epoch 103 : Loss 0.9999719262123108\n",
      "Epoch 104 : Loss 0.9999708533287048\n",
      "Epoch 105 : Loss 0.9999696612358093\n",
      "Epoch 106 : Loss 0.999968409538269\n",
      "Epoch 107 : Loss 0.9999672174453735\n",
      "Epoch 108 : Loss 0.9999659061431885\n",
      "Epoch 109 : Loss 0.9999645352363586\n",
      "Epoch 110 : Loss 0.999963104724884\n",
      "Epoch 111 : Loss 0.9999616742134094\n",
      "Epoch 112 : Loss 0.99996018409729\n",
      "Epoch 113 : Loss 0.9999586343765259\n",
      "Epoch 114 : Loss 0.9999569654464722\n",
      "Epoch 115 : Loss 0.9999553561210632\n",
      "Epoch 116 : Loss 0.99995356798172\n",
      "Epoch 117 : Loss 0.9999517798423767\n",
      "Epoch 118 : Loss 0.9999499320983887\n",
      "Epoch 119 : Loss 0.9999480247497559\n",
      "Epoch 120 : Loss 0.9999459981918335\n",
      "Epoch 121 : Loss 0.9999439120292664\n",
      "Epoch 122 : Loss 0.9999416470527649\n",
      "Epoch 123 : Loss 0.999939501285553\n",
      "Epoch 124 : Loss 0.9999370574951172\n",
      "Epoch 125 : Loss 0.9999346733093262\n",
      "Epoch 126 : Loss 0.9999322891235352\n",
      "Epoch 127 : Loss 0.9999296069145203\n",
      "Epoch 128 : Loss 0.9999269843101501\n",
      "Epoch 129 : Loss 0.9999242424964905\n",
      "Epoch 130 : Loss 0.9999213218688965\n",
      "Epoch 131 : Loss 0.9999183416366577\n",
      "Epoch 132 : Loss 0.9999152421951294\n",
      "Epoch 133 : Loss 0.9999119639396667\n",
      "Epoch 134 : Loss 0.9999086260795593\n",
      "Epoch 135 : Loss 0.9999051690101624\n",
      "Epoch 136 : Loss 0.999901533126831\n",
      "Epoch 137 : Loss 0.9998977184295654\n",
      "Epoch 138 : Loss 0.9998937845230103\n",
      "Epoch 139 : Loss 0.9998897910118103\n",
      "Epoch 140 : Loss 0.999885618686676\n",
      "Epoch 141 : Loss 0.9998812079429626\n",
      "Epoch 142 : Loss 0.9998766183853149\n",
      "Epoch 143 : Loss 0.9998719692230225\n",
      "Epoch 144 : Loss 0.9998669624328613\n",
      "Epoch 145 : Loss 0.9998618960380554\n",
      "Epoch 146 : Loss 0.9998565316200256\n",
      "Epoch 147 : Loss 0.9998510479927063\n",
      "Epoch 148 : Loss 0.9998452067375183\n",
      "Epoch 149 : Loss 0.9998390674591064\n",
      "Epoch 150 : Loss 0.9998328685760498\n",
      "Epoch 151 : Loss 0.9998264312744141\n",
      "Epoch 152 : Loss 0.9998195171356201\n",
      "Epoch 153 : Loss 0.9998124837875366\n",
      "Epoch 154 : Loss 0.9998050928115845\n",
      "Epoch 155 : Loss 0.9997973442077637\n",
      "Epoch 156 : Loss 0.9997893571853638\n",
      "Epoch 157 : Loss 0.9997808933258057\n",
      "Epoch 158 : Loss 0.9997720718383789\n",
      "Epoch 159 : Loss 0.999762773513794\n",
      "Epoch 160 : Loss 0.9997532367706299\n",
      "Epoch 161 : Loss 0.9997432231903076\n",
      "Epoch 162 : Loss 0.9997327327728271\n",
      "Epoch 163 : Loss 0.9997217655181885\n",
      "Epoch 164 : Loss 0.999710202217102\n",
      "Epoch 165 : Loss 0.9996984004974365\n",
      "Epoch 166 : Loss 0.9996857643127441\n",
      "Epoch 167 : Loss 0.999672532081604\n",
      "Epoch 168 : Loss 0.9996585249900818\n",
      "Epoch 169 : Loss 0.9996441006660461\n",
      "Epoch 170 : Loss 0.9996288418769836\n",
      "Epoch 171 : Loss 0.9996129274368286\n",
      "Epoch 172 : Loss 0.999596118927002\n",
      "Epoch 173 : Loss 0.9995784759521484\n",
      "Epoch 174 : Loss 0.9995596408843994\n",
      "Epoch 175 : Loss 0.9995400905609131\n",
      "Epoch 176 : Loss 0.9995194673538208\n",
      "Epoch 177 : Loss 0.9994975924491882\n",
      "Epoch 178 : Loss 0.9994747638702393\n",
      "Epoch 179 : Loss 0.9994504451751709\n",
      "Epoch 180 : Loss 0.9994248747825623\n",
      "Epoch 181 : Loss 0.9993978142738342\n",
      "Epoch 182 : Loss 0.9993690252304077\n",
      "Epoch 183 : Loss 0.9993386268615723\n",
      "Epoch 184 : Loss 0.9993063807487488\n",
      "Epoch 185 : Loss 0.9992722272872925\n",
      "Epoch 186 : Loss 0.9992358088493347\n",
      "Epoch 187 : Loss 0.9991971254348755\n",
      "Epoch 188 : Loss 0.9991559982299805\n",
      "Epoch 189 : Loss 0.9991121292114258\n",
      "Epoch 190 : Loss 0.9990652799606323\n",
      "Epoch 191 : Loss 0.9990151524543762\n",
      "Epoch 192 : Loss 0.9989615678787231\n",
      "Epoch 193 : Loss 0.9989039897918701\n",
      "Epoch 194 : Loss 0.9988424777984619\n",
      "Epoch 195 : Loss 0.9987761974334717\n",
      "Epoch 196 : Loss 0.998704731464386\n",
      "Epoch 197 : Loss 0.9986277222633362\n",
      "Epoch 198 : Loss 0.9985445737838745\n",
      "Epoch 199 : Loss 0.9984544515609741\n",
      "Epoch 200 : Loss 0.998356819152832\n",
      "Epoch 201 : Loss 0.9982503652572632\n",
      "Epoch 202 : Loss 0.9981347322463989\n",
      "Epoch 203 : Loss 0.9980083703994751\n",
      "Epoch 204 : Loss 0.9978697896003723\n",
      "Epoch 205 : Loss 0.9977176189422607\n",
      "Epoch 206 : Loss 0.9975501298904419\n",
      "Epoch 207 : Loss 0.9973649978637695\n",
      "Epoch 208 : Loss 0.997160017490387\n",
      "Epoch 209 : Loss 0.996931791305542\n",
      "Epoch 210 : Loss 0.9966771602630615\n",
      "Epoch 211 : Loss 0.996391773223877\n",
      "Epoch 212 : Loss 0.9960700273513794\n",
      "Epoch 213 : Loss 0.9957064390182495\n",
      "Epoch 214 : Loss 0.9952927827835083\n",
      "Epoch 215 : Loss 0.9948197603225708\n",
      "Epoch 216 : Loss 0.9942754507064819\n",
      "Epoch 217 : Loss 0.9936449527740479\n",
      "Epoch 218 : Loss 0.9929093718528748\n",
      "Epoch 219 : Loss 0.99204421043396\n",
      "Epoch 220 : Loss 0.99101722240448\n",
      "Epoch 221 : Loss 0.9897864460945129\n",
      "Epoch 222 : Loss 0.9882944822311401\n",
      "Epoch 223 : Loss 0.9864633679389954\n",
      "Epoch 224 : Loss 0.9841839075088501\n",
      "Epoch 225 : Loss 0.9813010692596436\n",
      "Epoch 226 : Loss 0.9775866866111755\n",
      "Epoch 227 : Loss 0.9727000594139099\n",
      "Epoch 228 : Loss 0.9661140441894531\n",
      "Epoch 229 : Loss 0.9569881558418274\n",
      "Epoch 230 : Loss 0.9439390301704407\n",
      "Epoch 231 : Loss 0.9246283173561096\n",
      "Epoch 232 : Loss 0.8950639367103577\n",
      "Epoch 233 : Loss 0.8487411737442017\n",
      "Epoch 234 : Loss 0.7772836685180664\n",
      "Epoch 235 : Loss 0.6793739199638367\n",
      "Epoch 236 : Loss 0.5817416906356812\n",
      "Epoch 237 : Loss 0.5245391130447388\n",
      "Epoch 238 : Loss 0.5053656697273254\n",
      "Epoch 239 : Loss 0.5009862780570984\n",
      "Epoch 240 : Loss 0.5001643300056458\n",
      "Epoch 241 : Loss 0.5000224709510803\n",
      "Epoch 242 : Loss 0.49999839067459106\n",
      "Epoch 243 : Loss 0.49999403953552246\n",
      "Epoch 244 : Loss 0.4999927580356598\n",
      "Epoch 245 : Loss 0.49999189376831055\n",
      "Epoch 246 : Loss 0.49999111890792847\n",
      "Epoch 247 : Loss 0.4999903738498688\n",
      "Epoch 248 : Loss 0.49998950958251953\n",
      "Epoch 249 : Loss 0.4999886155128479\n",
      "Epoch 250 : Loss 0.4999876320362091\n",
      "Epoch 251 : Loss 0.49998655915260315\n",
      "Epoch 252 : Loss 0.4999854564666748\n",
      "Epoch 253 : Loss 0.4999842345714569\n",
      "Epoch 254 : Loss 0.49998289346694946\n",
      "Epoch 255 : Loss 0.49998146295547485\n",
      "Epoch 256 : Loss 0.4999798834323883\n",
      "Epoch 257 : Loss 0.4999782145023346\n",
      "Epoch 258 : Loss 0.49997639656066895\n",
      "Epoch 259 : Loss 0.4999743700027466\n",
      "Epoch 260 : Loss 0.49997231364250183\n",
      "Epoch 261 : Loss 0.49997004866600037\n",
      "Epoch 262 : Loss 0.4999675452709198\n",
      "Epoch 263 : Loss 0.4999649226665497\n",
      "Epoch 264 : Loss 0.4999619126319885\n",
      "Epoch 265 : Loss 0.4999588131904602\n",
      "Epoch 266 : Loss 0.4999554753303528\n",
      "Epoch 267 : Loss 0.4999517798423767\n",
      "Epoch 268 : Loss 0.49994784593582153\n",
      "Epoch 269 : Loss 0.4999435245990753\n",
      "Epoch 270 : Loss 0.49993887543678284\n",
      "Epoch 271 : Loss 0.4999338686466217\n",
      "Epoch 272 : Loss 0.49992838501930237\n",
      "Epoch 273 : Loss 0.4999225437641144\n",
      "Epoch 274 : Loss 0.49991610646247864\n",
      "Epoch 275 : Loss 0.4999091923236847\n",
      "Epoch 276 : Loss 0.499901682138443\n",
      "Epoch 277 : Loss 0.49989357590675354\n",
      "Epoch 278 : Loss 0.4998847544193268\n",
      "Epoch 279 : Loss 0.4998752176761627\n",
      "Epoch 280 : Loss 0.4998648166656494\n",
      "Epoch 281 : Loss 0.49985361099243164\n",
      "Epoch 282 : Loss 0.49984145164489746\n",
      "Epoch 283 : Loss 0.4998282194137573\n",
      "Epoch 284 : Loss 0.4998140037059784\n",
      "Epoch 285 : Loss 0.49979838728904724\n",
      "Epoch 286 : Loss 0.49978145956993103\n",
      "Epoch 287 : Loss 0.49976322054862976\n",
      "Epoch 288 : Loss 0.49974319338798523\n",
      "Epoch 289 : Loss 0.499721497297287\n",
      "Epoch 290 : Loss 0.49969810247421265\n",
      "Epoch 291 : Loss 0.49967247247695923\n",
      "Epoch 292 : Loss 0.4996444582939148\n",
      "Epoch 293 : Loss 0.4996141195297241\n",
      "Epoch 294 : Loss 0.49958112835884094\n",
      "Epoch 295 : Loss 0.49954500794410706\n",
      "Epoch 296 : Loss 0.4995056390762329\n",
      "Epoch 297 : Loss 0.4994628131389618\n",
      "Epoch 298 : Loss 0.4994158148765564\n",
      "Epoch 299 : Loss 0.4993645250797272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 : Loss 0.49930834770202637\n",
      "Epoch 301 : Loss 0.49924689531326294\n",
      "Epoch 302 : Loss 0.4991793930530548\n",
      "Epoch 303 : Loss 0.49910542368888855\n",
      "Epoch 304 : Loss 0.49902403354644775\n",
      "Epoch 305 : Loss 0.4989345371723175\n",
      "Epoch 306 : Loss 0.4988357126712799\n",
      "Epoch 307 : Loss 0.49872663617134094\n",
      "Epoch 308 : Loss 0.4986061751842499\n",
      "Epoch 309 : Loss 0.4984724819660187\n",
      "Epoch 310 : Loss 0.49832406640052795\n",
      "Epoch 311 : Loss 0.49815890192985535\n",
      "Epoch 312 : Loss 0.49797460436820984\n",
      "Epoch 313 : Loss 0.4977684020996094\n",
      "Epoch 314 : Loss 0.4975370764732361\n",
      "Epoch 315 : Loss 0.49727663397789\n",
      "Epoch 316 : Loss 0.49698248505592346\n",
      "Epoch 317 : Loss 0.4966489374637604\n",
      "Epoch 318 : Loss 0.4962691068649292\n",
      "Epoch 319 : Loss 0.4958345890045166\n",
      "Epoch 320 : Loss 0.4953348934650421\n",
      "Epoch 321 : Loss 0.494756817817688\n",
      "Epoch 322 : Loss 0.4940842092037201\n",
      "Epoch 323 : Loss 0.4932958781719208\n",
      "Epoch 324 : Loss 0.49236488342285156\n",
      "Epoch 325 : Loss 0.4912557005882263\n",
      "Epoch 326 : Loss 0.4899212121963501\n",
      "Epoch 327 : Loss 0.4882982075214386\n",
      "Epoch 328 : Loss 0.48629966378211975\n",
      "Epoch 329 : Loss 0.48380404710769653\n",
      "Epoch 330 : Loss 0.4806371033191681\n",
      "Epoch 331 : Loss 0.4765441417694092\n",
      "Epoch 332 : Loss 0.4711422324180603\n",
      "Epoch 333 : Loss 0.4638383388519287\n",
      "Epoch 334 : Loss 0.4536873400211334\n",
      "Epoch 335 : Loss 0.43913695216178894\n",
      "Epoch 336 : Loss 0.4175839126110077\n",
      "Epoch 337 : Loss 0.3846707046031952\n",
      "Epoch 338 : Loss 0.33364713191986084\n",
      "Epoch 339 : Loss 0.257110059261322\n",
      "Epoch 340 : Loss 0.15822471678256989\n",
      "Epoch 341 : Loss 0.06821286678314209\n",
      "Epoch 342 : Loss 0.0199316143989563\n",
      "Epoch 343 : Loss 0.004409903660416603\n",
      "Epoch 344 : Loss 0.0008421370876021683\n",
      "Epoch 345 : Loss 0.00015038107812870294\n",
      "Epoch 346 : Loss 2.6091080144396983e-05\n",
      "Epoch 347 : Loss 4.472525688470341e-06\n",
      "Epoch 348 : Loss 7.628731850672921e-07\n",
      "Epoch 349 : Loss 1.2985772457341227e-07\n",
      "Epoch 350 : Loss 2.209244698292423e-08\n",
      "Epoch 351 : Loss 3.763083178398574e-09\n",
      "Epoch 352 : Loss 6.462606005896987e-10\n",
      "Epoch 353 : Loss 1.1598205729157485e-10\n",
      "Epoch 354 : Loss 2.5475007520148196e-11\n",
      "Epoch 355 : Loss 9.808489090379346e-12\n",
      "Epoch 356 : Loss 6.9469655722409485e-12\n",
      "Epoch 357 : Loss 6.340883547395482e-12\n",
      "Epoch 358 : Loss 6.193971117257613e-12\n",
      "Epoch 359 : Loss 6.198072003554822e-12\n",
      "Epoch 360 : Loss 6.2996079706889585e-12\n",
      "Epoch 361 : Loss 6.488884516514526e-12\n",
      "Epoch 362 : Loss 6.7649883091214225e-12\n",
      "Epoch 363 : Loss 7.1293843224851106e-12\n",
      "Epoch 364 : Loss 7.584760076950747e-12\n",
      "Epoch 365 : Loss 8.135524372232528e-12\n",
      "Epoch 366 : Loss 8.786864465204491e-12\n",
      "Epoch 367 : Loss 9.545211843153822e-12\n",
      "Epoch 368 : Loss 1.0418722308502826e-11\n",
      "Epoch 369 : Loss 1.1416881329218143e-11\n",
      "Epoch 370 : Loss 1.255031842339882e-11\n",
      "Epoch 371 : Loss 1.3831816768339333e-11\n",
      "Epoch 372 : Loss 1.5275603698627904e-11\n",
      "Epoch 373 : Loss 1.6897394941595145e-11\n",
      "Epoch 374 : Loss 1.8716223015857736e-11\n",
      "Epoch 375 : Loss 2.0752651333499905e-11\n",
      "Epoch 376 : Loss 2.3029056092638278e-11\n",
      "Epoch 377 : Loss 2.5572540612861516e-11\n",
      "Epoch 378 : Loss 2.8411347927081998e-11\n",
      "Epoch 379 : Loss 3.15777577697407e-11\n",
      "Epoch 380 : Loss 3.510889148850005e-11\n",
      "Epoch 381 : Loss 3.904427822720713e-11\n",
      "Epoch 382 : Loss 4.34304606167224e-11\n",
      "Epoch 383 : Loss 4.831680888717216e-11\n",
      "Epoch 384 : Loss 5.375815764763203e-11\n",
      "Epoch 385 : Loss 5.981951045619383e-11\n",
      "Epoch 386 : Loss 6.656877826749508e-11\n",
      "Epoch 387 : Loss 7.408431507149871e-11\n",
      "Epoch 388 : Loss 8.245195498579605e-11\n",
      "Epoch 389 : Loss 9.17697168256737e-11\n",
      "Epoch 390 : Loss 1.0214170481637197e-10\n",
      "Epoch 391 : Loss 1.1368751079432471e-10\n",
      "Epoch 392 : Loss 1.2654288727986795e-10\n",
      "Epoch 393 : Loss 1.4085552169085247e-10\n",
      "Epoch 394 : Loss 1.5678577880429145e-10\n",
      "Epoch 395 : Loss 1.7451984302141454e-10\n",
      "Epoch 396 : Loss 1.9426121822263553e-10\n",
      "Epoch 397 : Loss 2.1623640378276576e-10\n",
      "Epoch 398 : Loss 2.4069760073963664e-10\n",
      "Epoch 399 : Loss 2.6792926210994494e-10\n",
      "Epoch 400 : Loss 2.982404323503829e-10\n",
      "Epoch 401 : Loss 3.3197750104463353e-10\n",
      "Epoch 402 : Loss 3.695406758374986e-10\n",
      "Epoch 403 : Loss 4.1134909367634975e-10\n",
      "Epoch 404 : Loss 4.5789483316127644e-10\n",
      "Epoch 405 : Loss 5.096932875758853e-10\n",
      "Epoch 406 : Loss 5.673709280173966e-10\n",
      "Epoch 407 : Loss 6.315565848069582e-10\n",
      "Epoch 408 : Loss 7.030154791642929e-10\n",
      "Epoch 409 : Loss 7.825435299757544e-10\n",
      "Epoch 410 : Loss 8.711012466910972e-10\n",
      "Epoch 411 : Loss 9.69660463034927e-10\n",
      "Epoch 412 : Loss 1.0793606008974166e-09\n",
      "Epoch 413 : Loss 1.2014915728997266e-09\n",
      "Epoch 414 : Loss 1.337423949365757e-09\n",
      "Epoch 415 : Loss 1.4887292509868644e-09\n",
      "Epoch 416 : Loss 1.6571671812570798e-09\n",
      "Epoch 417 : Loss 1.844690400432114e-09\n",
      "Epoch 418 : Loss 2.053345937724771e-09\n",
      "Epoch 419 : Loss 2.285668321277967e-09\n",
      "Epoch 420 : Loss 2.544299437801101e-09\n",
      "Epoch 421 : Loss 2.832103218608495e-09\n",
      "Epoch 422 : Loss 3.1525266841470057e-09\n",
      "Epoch 423 : Loss 3.5092140304726627e-09\n",
      "Epoch 424 : Loss 3.906242884710309e-09\n",
      "Epoch 425 : Loss 4.348196025460993e-09\n",
      "Epoch 426 : Loss 4.840131406780301e-09\n",
      "Epoch 427 : Loss 5.387781332188979e-09\n",
      "Epoch 428 : Loss 5.997301322224757e-09\n",
      "Epoch 429 : Loss 6.675872299410912e-09\n",
      "Epoch 430 : Loss 7.431061543883288e-09\n",
      "Epoch 431 : Loss 8.271784146529626e-09\n",
      "Epoch 432 : Loss 9.207509421571558e-09\n",
      "Epoch 433 : Loss 1.0249254778216255e-08\n",
      "Epoch 434 : Loss 1.1408792133238421e-08\n",
      "Epoch 435 : Loss 1.2699426399365166e-08\n",
      "Epoch 436 : Loss 1.4136105619400041e-08\n",
      "Epoch 437 : Loss 1.5735121650095607e-08\n",
      "Epoch 438 : Loss 1.751532607841e-08\n",
      "Epoch 439 : Loss 1.9496619430015016e-08\n",
      "Epoch 440 : Loss 2.17016360437583e-08\n",
      "Epoch 441 : Loss 2.4157060352081317e-08\n",
      "Epoch 442 : Loss 2.688960343277813e-08\n",
      "Epoch 443 : Loss 2.9931715772590906e-08\n",
      "Epoch 444 : Loss 3.3316929659577e-08\n",
      "Epoch 445 : Loss 3.708593965257023e-08\n",
      "Epoch 446 : Loss 4.128109054590823e-08\n",
      "Epoch 447 : Loss 4.595020186570764e-08\n",
      "Epoch 448 : Loss 5.114801382433143e-08\n",
      "Epoch 449 : Loss 5.693276605711617e-08\n",
      "Epoch 450 : Loss 6.33722905263312e-08\n",
      "Epoch 451 : Loss 7.054033090980738e-08\n",
      "Epoch 452 : Loss 7.851880212683682e-08\n",
      "Epoch 453 : Loss 8.739829837622892e-08\n",
      "Epoch 454 : Loss 9.728451999535537e-08\n",
      "Epoch 455 : Loss 1.0828362206893871e-07\n",
      "Epoch 456 : Loss 1.2053010323143099e-07\n",
      "Epoch 457 : Loss 1.341594355608322e-07\n",
      "Epoch 458 : Loss 1.4933206671230437e-07\n",
      "Epoch 459 : Loss 1.662169495375565e-07\n",
      "Epoch 460 : Loss 1.850131923220033e-07\n",
      "Epoch 461 : Loss 2.0593191152329382e-07\n",
      "Epoch 462 : Loss 2.2921496167782607e-07\n",
      "Epoch 463 : Loss 2.5513139689792297e-07\n",
      "Epoch 464 : Loss 2.839736907844781e-07\n",
      "Epoch 465 : Loss 3.1607942219125107e-07\n",
      "Epoch 466 : Loss 3.5180667623535555e-07\n",
      "Epoch 467 : Loss 3.9156591924438544e-07\n",
      "Epoch 468 : Loss 4.358304011020664e-07\n",
      "Epoch 469 : Loss 4.850888331020542e-07\n",
      "Epoch 470 : Loss 5.399041924647463e-07\n",
      "Epoch 471 : Loss 6.009216235725034e-07\n",
      "Epoch 472 : Loss 6.688193252557539e-07\n",
      "Epoch 473 : Loss 7.443951517416281e-07\n",
      "Epoch 474 : Loss 8.284909540634544e-07\n",
      "Epoch 475 : Loss 9.220715355695575e-07\n",
      "Epoch 476 : Loss 1.026218342303764e-06\n",
      "Epoch 477 : Loss 1.1421058161431574e-06\n",
      "Epoch 478 : Loss 1.2711057024716865e-06\n",
      "Epoch 479 : Loss 1.4146278317639371e-06\n",
      "Epoch 480 : Loss 1.5743399899292854e-06\n",
      "Epoch 481 : Loss 1.7520561641504173e-06\n",
      "Epoch 482 : Loss 1.9497711036819965e-06\n",
      "Epoch 483 : Loss 2.169811295971158e-06\n",
      "Epoch 484 : Loss 2.4146634132193867e-06\n",
      "Epoch 485 : Loss 2.687035703274887e-06\n",
      "Epoch 486 : Loss 2.990074790432118e-06\n",
      "Epoch 487 : Loss 3.32717968376528e-06\n",
      "Epoch 488 : Loss 3.7022150536358822e-06\n",
      "Epoch 489 : Loss 4.119513960176846e-06\n",
      "Epoch 490 : Loss 4.583565896609798e-06\n",
      "Epoch 491 : Loss 5.099725058244076e-06\n",
      "Epoch 492 : Loss 5.67381948712864e-06\n",
      "Epoch 493 : Loss 6.312505320238415e-06\n",
      "Epoch 494 : Loss 7.022635600151261e-06\n",
      "Epoch 495 : Loss 7.812427611497696e-06\n",
      "Epoch 496 : Loss 8.69071482156869e-06\n",
      "Epoch 497 : Loss 9.66701190918684e-06\n",
      "Epoch 498 : Loss 1.0752433809102513e-05\n",
      "Epoch 499 : Loss 1.1959160474361852e-05\n"
     ]
    }
   ],
   "source": [
    "y_goal=np.array([[0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [1],\n",
    "                 [0],\n",
    "                 [0]])\n",
    "image = train(500,torch.tensor([0.001]),torch.as_tensor(y_goal,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d49bd080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.view(28,28).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset = torchvision.datasets.MNIST(root='sudo /files/', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('sudo /files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('sudo /files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1651b6f28>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1651b6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc1650a8ba8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc164ee7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_target = example_data[10][0]\n",
    "print(type(x_target))\n",
    "plt.imshow(x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Loss tensor([63.5756], grad_fn=<AddBackward0>)\n",
      "Epoch 1 : Loss tensor([63.5754], grad_fn=<AddBackward0>)\n",
      "Epoch 2 : Loss tensor([63.5750], grad_fn=<AddBackward0>)\n",
      "Epoch 3 : Loss tensor([63.5744], grad_fn=<AddBackward0>)\n",
      "Epoch 4 : Loss tensor([63.5736], grad_fn=<AddBackward0>)\n",
      "Epoch 5 : Loss tensor([63.5726], grad_fn=<AddBackward0>)\n",
      "Epoch 6 : Loss tensor([63.5715], grad_fn=<AddBackward0>)\n",
      "Epoch 7 : Loss tensor([63.5701], grad_fn=<AddBackward0>)\n",
      "Epoch 8 : Loss tensor([63.5685], grad_fn=<AddBackward0>)\n",
      "Epoch 9 : Loss tensor([63.5668], grad_fn=<AddBackward0>)\n",
      "Epoch 10 : Loss tensor([63.5648], grad_fn=<AddBackward0>)\n",
      "Epoch 11 : Loss tensor([63.5627], grad_fn=<AddBackward0>)\n",
      "Epoch 12 : Loss tensor([63.5604], grad_fn=<AddBackward0>)\n",
      "Epoch 13 : Loss tensor([63.5579], grad_fn=<AddBackward0>)\n",
      "Epoch 14 : Loss tensor([63.5552], grad_fn=<AddBackward0>)\n",
      "Epoch 15 : Loss tensor([63.5523], grad_fn=<AddBackward0>)\n",
      "Epoch 16 : Loss tensor([63.5493], grad_fn=<AddBackward0>)\n",
      "Epoch 17 : Loss tensor([63.5460], grad_fn=<AddBackward0>)\n",
      "Epoch 18 : Loss tensor([63.5426], grad_fn=<AddBackward0>)\n",
      "Epoch 19 : Loss tensor([63.5390], grad_fn=<AddBackward0>)\n",
      "Epoch 20 : Loss tensor([63.5352], grad_fn=<AddBackward0>)\n",
      "Epoch 21 : Loss tensor([63.5312], grad_fn=<AddBackward0>)\n",
      "Epoch 22 : Loss tensor([63.5271], grad_fn=<AddBackward0>)\n",
      "Epoch 23 : Loss tensor([63.5227], grad_fn=<AddBackward0>)\n",
      "Epoch 24 : Loss tensor([63.5183], grad_fn=<AddBackward0>)\n",
      "Epoch 25 : Loss tensor([63.5136], grad_fn=<AddBackward0>)\n",
      "Epoch 26 : Loss tensor([63.5088], grad_fn=<AddBackward0>)\n",
      "Epoch 27 : Loss tensor([63.5038], grad_fn=<AddBackward0>)\n",
      "Epoch 28 : Loss tensor([63.4986], grad_fn=<AddBackward0>)\n",
      "Epoch 29 : Loss tensor([63.4933], grad_fn=<AddBackward0>)\n",
      "Epoch 30 : Loss tensor([63.4878], grad_fn=<AddBackward0>)\n",
      "Epoch 31 : Loss tensor([63.4822], grad_fn=<AddBackward0>)\n",
      "Epoch 32 : Loss tensor([63.4764], grad_fn=<AddBackward0>)\n",
      "Epoch 33 : Loss tensor([63.4704], grad_fn=<AddBackward0>)\n",
      "Epoch 34 : Loss tensor([63.4643], grad_fn=<AddBackward0>)\n",
      "Epoch 35 : Loss tensor([63.4580], grad_fn=<AddBackward0>)\n",
      "Epoch 36 : Loss tensor([63.4515], grad_fn=<AddBackward0>)\n",
      "Epoch 37 : Loss tensor([63.4449], grad_fn=<AddBackward0>)\n",
      "Epoch 38 : Loss tensor([63.4382], grad_fn=<AddBackward0>)\n",
      "Epoch 39 : Loss tensor([63.4313], grad_fn=<AddBackward0>)\n",
      "Epoch 40 : Loss tensor([63.4242], grad_fn=<AddBackward0>)\n",
      "Epoch 41 : Loss tensor([63.4170], grad_fn=<AddBackward0>)\n",
      "Epoch 42 : Loss tensor([63.4096], grad_fn=<AddBackward0>)\n",
      "Epoch 43 : Loss tensor([63.4021], grad_fn=<AddBackward0>)\n",
      "Epoch 44 : Loss tensor([63.3944], grad_fn=<AddBackward0>)\n",
      "Epoch 45 : Loss tensor([63.3866], grad_fn=<AddBackward0>)\n",
      "Epoch 46 : Loss tensor([63.3786], grad_fn=<AddBackward0>)\n",
      "Epoch 47 : Loss tensor([63.3704], grad_fn=<AddBackward0>)\n",
      "Epoch 48 : Loss tensor([63.3621], grad_fn=<AddBackward0>)\n",
      "Epoch 49 : Loss tensor([63.3536], grad_fn=<AddBackward0>)\n",
      "Epoch 50 : Loss tensor([63.3450], grad_fn=<AddBackward0>)\n",
      "Epoch 51 : Loss tensor([63.3362], grad_fn=<AddBackward0>)\n",
      "Epoch 52 : Loss tensor([63.3272], grad_fn=<AddBackward0>)\n",
      "Epoch 53 : Loss tensor([63.3181], grad_fn=<AddBackward0>)\n",
      "Epoch 54 : Loss tensor([63.3088], grad_fn=<AddBackward0>)\n",
      "Epoch 55 : Loss tensor([63.2993], grad_fn=<AddBackward0>)\n",
      "Epoch 56 : Loss tensor([63.2896], grad_fn=<AddBackward0>)\n",
      "Epoch 57 : Loss tensor([63.2798], grad_fn=<AddBackward0>)\n",
      "Epoch 58 : Loss tensor([63.2698], grad_fn=<AddBackward0>)\n",
      "Epoch 59 : Loss tensor([63.2596], grad_fn=<AddBackward0>)\n",
      "Epoch 60 : Loss tensor([63.2491], grad_fn=<AddBackward0>)\n",
      "Epoch 61 : Loss tensor([63.2385], grad_fn=<AddBackward0>)\n",
      "Epoch 62 : Loss tensor([63.2277], grad_fn=<AddBackward0>)\n",
      "Epoch 63 : Loss tensor([63.2168], grad_fn=<AddBackward0>)\n",
      "Epoch 64 : Loss tensor([63.2056], grad_fn=<AddBackward0>)\n",
      "Epoch 65 : Loss tensor([63.1941], grad_fn=<AddBackward0>)\n",
      "Epoch 66 : Loss tensor([63.1825], grad_fn=<AddBackward0>)\n",
      "Epoch 67 : Loss tensor([63.1706], grad_fn=<AddBackward0>)\n",
      "Epoch 68 : Loss tensor([63.1585], grad_fn=<AddBackward0>)\n",
      "Epoch 69 : Loss tensor([63.1462], grad_fn=<AddBackward0>)\n",
      "Epoch 70 : Loss tensor([63.1336], grad_fn=<AddBackward0>)\n",
      "Epoch 71 : Loss tensor([63.1207], grad_fn=<AddBackward0>)\n",
      "Epoch 72 : Loss tensor([63.1076], grad_fn=<AddBackward0>)\n",
      "Epoch 73 : Loss tensor([63.0943], grad_fn=<AddBackward0>)\n",
      "Epoch 74 : Loss tensor([63.0806], grad_fn=<AddBackward0>)\n",
      "Epoch 75 : Loss tensor([63.0667], grad_fn=<AddBackward0>)\n",
      "Epoch 76 : Loss tensor([63.0525], grad_fn=<AddBackward0>)\n",
      "Epoch 77 : Loss tensor([63.0379], grad_fn=<AddBackward0>)\n",
      "Epoch 78 : Loss tensor([63.0231], grad_fn=<AddBackward0>)\n",
      "Epoch 79 : Loss tensor([63.0079], grad_fn=<AddBackward0>)\n",
      "Epoch 80 : Loss tensor([62.9924], grad_fn=<AddBackward0>)\n",
      "Epoch 81 : Loss tensor([62.9766], grad_fn=<AddBackward0>)\n",
      "Epoch 82 : Loss tensor([62.9604], grad_fn=<AddBackward0>)\n",
      "Epoch 83 : Loss tensor([62.9438], grad_fn=<AddBackward0>)\n",
      "Epoch 84 : Loss tensor([62.9269], grad_fn=<AddBackward0>)\n",
      "Epoch 85 : Loss tensor([62.9096], grad_fn=<AddBackward0>)\n",
      "Epoch 86 : Loss tensor([62.8919], grad_fn=<AddBackward0>)\n",
      "Epoch 87 : Loss tensor([62.8738], grad_fn=<AddBackward0>)\n",
      "Epoch 88 : Loss tensor([62.8553], grad_fn=<AddBackward0>)\n",
      "Epoch 89 : Loss tensor([62.8363], grad_fn=<AddBackward0>)\n",
      "Epoch 90 : Loss tensor([62.8169], grad_fn=<AddBackward0>)\n",
      "Epoch 91 : Loss tensor([62.7971], grad_fn=<AddBackward0>)\n",
      "Epoch 92 : Loss tensor([62.7768], grad_fn=<AddBackward0>)\n",
      "Epoch 93 : Loss tensor([62.7561], grad_fn=<AddBackward0>)\n",
      "Epoch 94 : Loss tensor([62.7349], grad_fn=<AddBackward0>)\n",
      "Epoch 95 : Loss tensor([62.7132], grad_fn=<AddBackward0>)\n",
      "Epoch 96 : Loss tensor([62.6911], grad_fn=<AddBackward0>)\n",
      "Epoch 97 : Loss tensor([62.6685], grad_fn=<AddBackward0>)\n",
      "Epoch 98 : Loss tensor([62.6454], grad_fn=<AddBackward0>)\n",
      "Epoch 99 : Loss tensor([62.6219], grad_fn=<AddBackward0>)\n",
      "Epoch 100 : Loss tensor([62.5979], grad_fn=<AddBackward0>)\n",
      "Epoch 101 : Loss tensor([62.5734], grad_fn=<AddBackward0>)\n",
      "Epoch 102 : Loss tensor([62.5486], grad_fn=<AddBackward0>)\n",
      "Epoch 103 : Loss tensor([62.5233], grad_fn=<AddBackward0>)\n",
      "Epoch 104 : Loss tensor([62.4976], grad_fn=<AddBackward0>)\n",
      "Epoch 105 : Loss tensor([62.4715], grad_fn=<AddBackward0>)\n",
      "Epoch 106 : Loss tensor([62.4451], grad_fn=<AddBackward0>)\n",
      "Epoch 107 : Loss tensor([62.4184], grad_fn=<AddBackward0>)\n",
      "Epoch 108 : Loss tensor([62.3913], grad_fn=<AddBackward0>)\n",
      "Epoch 109 : Loss tensor([62.3640], grad_fn=<AddBackward0>)\n",
      "Epoch 110 : Loss tensor([62.3365], grad_fn=<AddBackward0>)\n",
      "Epoch 111 : Loss tensor([62.3088], grad_fn=<AddBackward0>)\n",
      "Epoch 112 : Loss tensor([62.2809], grad_fn=<AddBackward0>)\n",
      "Epoch 113 : Loss tensor([62.2529], grad_fn=<AddBackward0>)\n",
      "Epoch 114 : Loss tensor([62.2248], grad_fn=<AddBackward0>)\n",
      "Epoch 115 : Loss tensor([62.1966], grad_fn=<AddBackward0>)\n",
      "Epoch 116 : Loss tensor([62.1684], grad_fn=<AddBackward0>)\n",
      "Epoch 117 : Loss tensor([62.1402], grad_fn=<AddBackward0>)\n",
      "Epoch 118 : Loss tensor([62.1120], grad_fn=<AddBackward0>)\n",
      "Epoch 119 : Loss tensor([62.0838], grad_fn=<AddBackward0>)\n",
      "Epoch 120 : Loss tensor([62.0557], grad_fn=<AddBackward0>)\n",
      "Epoch 121 : Loss tensor([62.0276], grad_fn=<AddBackward0>)\n",
      "Epoch 122 : Loss tensor([61.9996], grad_fn=<AddBackward0>)\n",
      "Epoch 123 : Loss tensor([61.9716], grad_fn=<AddBackward0>)\n",
      "Epoch 124 : Loss tensor([61.9437], grad_fn=<AddBackward0>)\n",
      "Epoch 125 : Loss tensor([61.9159], grad_fn=<AddBackward0>)\n",
      "Epoch 126 : Loss tensor([61.8881], grad_fn=<AddBackward0>)\n",
      "Epoch 127 : Loss tensor([61.8604], grad_fn=<AddBackward0>)\n",
      "Epoch 128 : Loss tensor([61.8328], grad_fn=<AddBackward0>)\n",
      "Epoch 129 : Loss tensor([61.8053], grad_fn=<AddBackward0>)\n",
      "Epoch 130 : Loss tensor([61.7779], grad_fn=<AddBackward0>)\n",
      "Epoch 131 : Loss tensor([61.7506], grad_fn=<AddBackward0>)\n",
      "Epoch 132 : Loss tensor([61.7234], grad_fn=<AddBackward0>)\n",
      "Epoch 133 : Loss tensor([61.6964], grad_fn=<AddBackward0>)\n",
      "Epoch 134 : Loss tensor([61.6695], grad_fn=<AddBackward0>)\n",
      "Epoch 135 : Loss tensor([61.6429], grad_fn=<AddBackward0>)\n",
      "Epoch 136 : Loss tensor([61.6164], grad_fn=<AddBackward0>)\n",
      "Epoch 137 : Loss tensor([61.5902], grad_fn=<AddBackward0>)\n",
      "Epoch 138 : Loss tensor([61.5642], grad_fn=<AddBackward0>)\n",
      "Epoch 139 : Loss tensor([61.5385], grad_fn=<AddBackward0>)\n",
      "Epoch 140 : Loss tensor([61.5131], grad_fn=<AddBackward0>)\n",
      "Epoch 141 : Loss tensor([61.4880], grad_fn=<AddBackward0>)\n",
      "Epoch 142 : Loss tensor([61.4633], grad_fn=<AddBackward0>)\n",
      "Epoch 143 : Loss tensor([61.4389], grad_fn=<AddBackward0>)\n",
      "Epoch 144 : Loss tensor([61.4149], grad_fn=<AddBackward0>)\n",
      "Epoch 145 : Loss tensor([61.3913], grad_fn=<AddBackward0>)\n",
      "Epoch 146 : Loss tensor([61.3680], grad_fn=<AddBackward0>)\n",
      "Epoch 147 : Loss tensor([61.3451], grad_fn=<AddBackward0>)\n",
      "Epoch 148 : Loss tensor([61.3225], grad_fn=<AddBackward0>)\n",
      "Epoch 149 : Loss tensor([61.3003], grad_fn=<AddBackward0>)\n",
      "Epoch 150 : Loss tensor([61.2783], grad_fn=<AddBackward0>)\n",
      "Epoch 151 : Loss tensor([61.2567], grad_fn=<AddBackward0>)\n",
      "Epoch 152 : Loss tensor([61.2353], grad_fn=<AddBackward0>)\n",
      "Epoch 153 : Loss tensor([61.2142], grad_fn=<AddBackward0>)\n",
      "Epoch 154 : Loss tensor([61.1933], grad_fn=<AddBackward0>)\n",
      "Epoch 155 : Loss tensor([61.1726], grad_fn=<AddBackward0>)\n",
      "Epoch 156 : Loss tensor([61.1521], grad_fn=<AddBackward0>)\n",
      "Epoch 157 : Loss tensor([61.1317], grad_fn=<AddBackward0>)\n",
      "Epoch 158 : Loss tensor([61.1114], grad_fn=<AddBackward0>)\n",
      "Epoch 159 : Loss tensor([61.0912], grad_fn=<AddBackward0>)\n",
      "Epoch 160 : Loss tensor([61.0712], grad_fn=<AddBackward0>)\n",
      "Epoch 161 : Loss tensor([61.0511], grad_fn=<AddBackward0>)\n",
      "Epoch 162 : Loss tensor([61.0311], grad_fn=<AddBackward0>)\n",
      "Epoch 163 : Loss tensor([61.0112], grad_fn=<AddBackward0>)\n",
      "Epoch 164 : Loss tensor([60.9912], grad_fn=<AddBackward0>)\n",
      "Epoch 165 : Loss tensor([60.9712], grad_fn=<AddBackward0>)\n",
      "Epoch 166 : Loss tensor([60.9513], grad_fn=<AddBackward0>)\n",
      "Epoch 167 : Loss tensor([60.9312], grad_fn=<AddBackward0>)\n",
      "Epoch 168 : Loss tensor([60.9112], grad_fn=<AddBackward0>)\n",
      "Epoch 169 : Loss tensor([60.8911], grad_fn=<AddBackward0>)\n",
      "Epoch 170 : Loss tensor([60.8709], grad_fn=<AddBackward0>)\n",
      "Epoch 171 : Loss tensor([60.8507], grad_fn=<AddBackward0>)\n",
      "Epoch 172 : Loss tensor([60.8303], grad_fn=<AddBackward0>)\n",
      "Epoch 173 : Loss tensor([60.8099], grad_fn=<AddBackward0>)\n",
      "Epoch 174 : Loss tensor([60.7895], grad_fn=<AddBackward0>)\n",
      "Epoch 175 : Loss tensor([60.7689], grad_fn=<AddBackward0>)\n",
      "Epoch 176 : Loss tensor([60.7482], grad_fn=<AddBackward0>)\n",
      "Epoch 177 : Loss tensor([60.7275], grad_fn=<AddBackward0>)\n",
      "Epoch 178 : Loss tensor([60.7066], grad_fn=<AddBackward0>)\n",
      "Epoch 179 : Loss tensor([60.6857], grad_fn=<AddBackward0>)\n",
      "Epoch 180 : Loss tensor([60.6646], grad_fn=<AddBackward0>)\n",
      "Epoch 181 : Loss tensor([60.6435], grad_fn=<AddBackward0>)\n",
      "Epoch 182 : Loss tensor([60.6223], grad_fn=<AddBackward0>)\n",
      "Epoch 183 : Loss tensor([60.6009], grad_fn=<AddBackward0>)\n",
      "Epoch 184 : Loss tensor([60.5795], grad_fn=<AddBackward0>)\n",
      "Epoch 185 : Loss tensor([60.5579], grad_fn=<AddBackward0>)\n",
      "Epoch 186 : Loss tensor([60.5362], grad_fn=<AddBackward0>)\n",
      "Epoch 187 : Loss tensor([60.5145], grad_fn=<AddBackward0>)\n",
      "Epoch 188 : Loss tensor([60.4926], grad_fn=<AddBackward0>)\n",
      "Epoch 189 : Loss tensor([60.4706], grad_fn=<AddBackward0>)\n",
      "Epoch 190 : Loss tensor([60.4485], grad_fn=<AddBackward0>)\n",
      "Epoch 191 : Loss tensor([60.4263], grad_fn=<AddBackward0>)\n",
      "Epoch 192 : Loss tensor([60.4039], grad_fn=<AddBackward0>)\n",
      "Epoch 193 : Loss tensor([60.3815], grad_fn=<AddBackward0>)\n",
      "Epoch 194 : Loss tensor([60.3590], grad_fn=<AddBackward0>)\n",
      "Epoch 195 : Loss tensor([60.3363], grad_fn=<AddBackward0>)\n",
      "Epoch 196 : Loss tensor([60.3136], grad_fn=<AddBackward0>)\n",
      "Epoch 197 : Loss tensor([60.2907], grad_fn=<AddBackward0>)\n",
      "Epoch 198 : Loss tensor([60.2677], grad_fn=<AddBackward0>)\n",
      "Epoch 199 : Loss tensor([60.2446], grad_fn=<AddBackward0>)\n",
      "Epoch 200 : Loss tensor([60.2215], grad_fn=<AddBackward0>)\n",
      "Epoch 201 : Loss tensor([60.1982], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 : Loss tensor([60.1747], grad_fn=<AddBackward0>)\n",
      "Epoch 203 : Loss tensor([60.1512], grad_fn=<AddBackward0>)\n",
      "Epoch 204 : Loss tensor([60.1276], grad_fn=<AddBackward0>)\n",
      "Epoch 205 : Loss tensor([60.1039], grad_fn=<AddBackward0>)\n",
      "Epoch 206 : Loss tensor([60.0800], grad_fn=<AddBackward0>)\n",
      "Epoch 207 : Loss tensor([60.0560], grad_fn=<AddBackward0>)\n",
      "Epoch 208 : Loss tensor([60.0320], grad_fn=<AddBackward0>)\n",
      "Epoch 209 : Loss tensor([60.0078], grad_fn=<AddBackward0>)\n",
      "Epoch 210 : Loss tensor([59.9835], grad_fn=<AddBackward0>)\n",
      "Epoch 211 : Loss tensor([59.9591], grad_fn=<AddBackward0>)\n",
      "Epoch 212 : Loss tensor([59.9346], grad_fn=<AddBackward0>)\n",
      "Epoch 213 : Loss tensor([59.9100], grad_fn=<AddBackward0>)\n",
      "Epoch 214 : Loss tensor([59.8853], grad_fn=<AddBackward0>)\n",
      "Epoch 215 : Loss tensor([59.8605], grad_fn=<AddBackward0>)\n",
      "Epoch 216 : Loss tensor([59.8355], grad_fn=<AddBackward0>)\n",
      "Epoch 217 : Loss tensor([59.8105], grad_fn=<AddBackward0>)\n",
      "Epoch 218 : Loss tensor([59.7853], grad_fn=<AddBackward0>)\n",
      "Epoch 219 : Loss tensor([59.7601], grad_fn=<AddBackward0>)\n",
      "Epoch 220 : Loss tensor([59.7347], grad_fn=<AddBackward0>)\n",
      "Epoch 221 : Loss tensor([59.7093], grad_fn=<AddBackward0>)\n",
      "Epoch 222 : Loss tensor([59.6837], grad_fn=<AddBackward0>)\n",
      "Epoch 223 : Loss tensor([59.6580], grad_fn=<AddBackward0>)\n",
      "Epoch 224 : Loss tensor([59.6322], grad_fn=<AddBackward0>)\n",
      "Epoch 225 : Loss tensor([59.6063], grad_fn=<AddBackward0>)\n",
      "Epoch 226 : Loss tensor([59.5803], grad_fn=<AddBackward0>)\n",
      "Epoch 227 : Loss tensor([59.5542], grad_fn=<AddBackward0>)\n",
      "Epoch 228 : Loss tensor([59.5279], grad_fn=<AddBackward0>)\n",
      "Epoch 229 : Loss tensor([59.5016], grad_fn=<AddBackward0>)\n",
      "Epoch 230 : Loss tensor([59.4751], grad_fn=<AddBackward0>)\n",
      "Epoch 231 : Loss tensor([59.4486], grad_fn=<AddBackward0>)\n",
      "Epoch 232 : Loss tensor([59.4220], grad_fn=<AddBackward0>)\n",
      "Epoch 233 : Loss tensor([59.3952], grad_fn=<AddBackward0>)\n",
      "Epoch 234 : Loss tensor([59.3683], grad_fn=<AddBackward0>)\n",
      "Epoch 235 : Loss tensor([59.3414], grad_fn=<AddBackward0>)\n",
      "Epoch 236 : Loss tensor([59.3143], grad_fn=<AddBackward0>)\n",
      "Epoch 237 : Loss tensor([59.2871], grad_fn=<AddBackward0>)\n",
      "Epoch 238 : Loss tensor([59.2598], grad_fn=<AddBackward0>)\n",
      "Epoch 239 : Loss tensor([59.2324], grad_fn=<AddBackward0>)\n",
      "Epoch 240 : Loss tensor([59.2049], grad_fn=<AddBackward0>)\n",
      "Epoch 241 : Loss tensor([59.1773], grad_fn=<AddBackward0>)\n",
      "Epoch 242 : Loss tensor([59.1496], grad_fn=<AddBackward0>)\n",
      "Epoch 243 : Loss tensor([59.1217], grad_fn=<AddBackward0>)\n",
      "Epoch 244 : Loss tensor([59.0938], grad_fn=<AddBackward0>)\n",
      "Epoch 245 : Loss tensor([59.0658], grad_fn=<AddBackward0>)\n",
      "Epoch 246 : Loss tensor([59.0377], grad_fn=<AddBackward0>)\n",
      "Epoch 247 : Loss tensor([59.0094], grad_fn=<AddBackward0>)\n",
      "Epoch 248 : Loss tensor([58.9811], grad_fn=<AddBackward0>)\n",
      "Epoch 249 : Loss tensor([58.9526], grad_fn=<AddBackward0>)\n",
      "Epoch 250 : Loss tensor([58.9241], grad_fn=<AddBackward0>)\n",
      "Epoch 251 : Loss tensor([58.8954], grad_fn=<AddBackward0>)\n",
      "Epoch 252 : Loss tensor([58.8666], grad_fn=<AddBackward0>)\n",
      "Epoch 253 : Loss tensor([58.8378], grad_fn=<AddBackward0>)\n",
      "Epoch 254 : Loss tensor([58.8088], grad_fn=<AddBackward0>)\n",
      "Epoch 255 : Loss tensor([58.7797], grad_fn=<AddBackward0>)\n",
      "Epoch 256 : Loss tensor([58.7505], grad_fn=<AddBackward0>)\n",
      "Epoch 257 : Loss tensor([58.7213], grad_fn=<AddBackward0>)\n",
      "Epoch 258 : Loss tensor([58.6919], grad_fn=<AddBackward0>)\n",
      "Epoch 259 : Loss tensor([58.6624], grad_fn=<AddBackward0>)\n",
      "Epoch 260 : Loss tensor([58.6328], grad_fn=<AddBackward0>)\n",
      "Epoch 261 : Loss tensor([58.6031], grad_fn=<AddBackward0>)\n",
      "Epoch 262 : Loss tensor([58.5733], grad_fn=<AddBackward0>)\n",
      "Epoch 263 : Loss tensor([58.5434], grad_fn=<AddBackward0>)\n",
      "Epoch 264 : Loss tensor([58.5134], grad_fn=<AddBackward0>)\n",
      "Epoch 265 : Loss tensor([58.4833], grad_fn=<AddBackward0>)\n",
      "Epoch 266 : Loss tensor([58.4531], grad_fn=<AddBackward0>)\n",
      "Epoch 267 : Loss tensor([58.4227], grad_fn=<AddBackward0>)\n",
      "Epoch 268 : Loss tensor([58.3923], grad_fn=<AddBackward0>)\n",
      "Epoch 269 : Loss tensor([58.3618], grad_fn=<AddBackward0>)\n",
      "Epoch 270 : Loss tensor([58.3312], grad_fn=<AddBackward0>)\n",
      "Epoch 271 : Loss tensor([58.3004], grad_fn=<AddBackward0>)\n",
      "Epoch 272 : Loss tensor([58.2696], grad_fn=<AddBackward0>)\n",
      "Epoch 273 : Loss tensor([58.2387], grad_fn=<AddBackward0>)\n",
      "Epoch 274 : Loss tensor([58.2077], grad_fn=<AddBackward0>)\n",
      "Epoch 275 : Loss tensor([58.1765], grad_fn=<AddBackward0>)\n",
      "Epoch 276 : Loss tensor([58.1453], grad_fn=<AddBackward0>)\n",
      "Epoch 277 : Loss tensor([58.1140], grad_fn=<AddBackward0>)\n",
      "Epoch 278 : Loss tensor([58.0825], grad_fn=<AddBackward0>)\n",
      "Epoch 279 : Loss tensor([58.0510], grad_fn=<AddBackward0>)\n",
      "Epoch 280 : Loss tensor([58.0194], grad_fn=<AddBackward0>)\n",
      "Epoch 281 : Loss tensor([57.9876], grad_fn=<AddBackward0>)\n",
      "Epoch 282 : Loss tensor([57.9558], grad_fn=<AddBackward0>)\n",
      "Epoch 283 : Loss tensor([57.9238], grad_fn=<AddBackward0>)\n",
      "Epoch 284 : Loss tensor([57.8918], grad_fn=<AddBackward0>)\n",
      "Epoch 285 : Loss tensor([57.8596], grad_fn=<AddBackward0>)\n",
      "Epoch 286 : Loss tensor([57.8274], grad_fn=<AddBackward0>)\n",
      "Epoch 287 : Loss tensor([57.7951], grad_fn=<AddBackward0>)\n",
      "Epoch 288 : Loss tensor([57.7626], grad_fn=<AddBackward0>)\n",
      "Epoch 289 : Loss tensor([57.7301], grad_fn=<AddBackward0>)\n",
      "Epoch 290 : Loss tensor([57.6974], grad_fn=<AddBackward0>)\n",
      "Epoch 291 : Loss tensor([57.6647], grad_fn=<AddBackward0>)\n",
      "Epoch 292 : Loss tensor([57.6319], grad_fn=<AddBackward0>)\n",
      "Epoch 293 : Loss tensor([57.5989], grad_fn=<AddBackward0>)\n",
      "Epoch 294 : Loss tensor([57.5659], grad_fn=<AddBackward0>)\n",
      "Epoch 295 : Loss tensor([57.5327], grad_fn=<AddBackward0>)\n",
      "Epoch 296 : Loss tensor([57.4995], grad_fn=<AddBackward0>)\n",
      "Epoch 297 : Loss tensor([57.4661], grad_fn=<AddBackward0>)\n",
      "Epoch 298 : Loss tensor([57.4327], grad_fn=<AddBackward0>)\n",
      "Epoch 299 : Loss tensor([57.3992], grad_fn=<AddBackward0>)\n",
      "Epoch 300 : Loss tensor([57.3655], grad_fn=<AddBackward0>)\n",
      "Epoch 301 : Loss tensor([57.3318], grad_fn=<AddBackward0>)\n",
      "Epoch 302 : Loss tensor([57.2980], grad_fn=<AddBackward0>)\n",
      "Epoch 303 : Loss tensor([57.2640], grad_fn=<AddBackward0>)\n",
      "Epoch 304 : Loss tensor([57.2300], grad_fn=<AddBackward0>)\n",
      "Epoch 305 : Loss tensor([57.1959], grad_fn=<AddBackward0>)\n",
      "Epoch 306 : Loss tensor([57.1617], grad_fn=<AddBackward0>)\n",
      "Epoch 307 : Loss tensor([57.1274], grad_fn=<AddBackward0>)\n",
      "Epoch 308 : Loss tensor([57.0929], grad_fn=<AddBackward0>)\n",
      "Epoch 309 : Loss tensor([57.0584], grad_fn=<AddBackward0>)\n",
      "Epoch 310 : Loss tensor([57.0238], grad_fn=<AddBackward0>)\n",
      "Epoch 311 : Loss tensor([56.9891], grad_fn=<AddBackward0>)\n",
      "Epoch 312 : Loss tensor([56.9543], grad_fn=<AddBackward0>)\n",
      "Epoch 313 : Loss tensor([56.9194], grad_fn=<AddBackward0>)\n",
      "Epoch 314 : Loss tensor([56.8844], grad_fn=<AddBackward0>)\n",
      "Epoch 315 : Loss tensor([56.8493], grad_fn=<AddBackward0>)\n",
      "Epoch 316 : Loss tensor([56.8141], grad_fn=<AddBackward0>)\n",
      "Epoch 317 : Loss tensor([56.7788], grad_fn=<AddBackward0>)\n",
      "Epoch 318 : Loss tensor([56.7435], grad_fn=<AddBackward0>)\n",
      "Epoch 319 : Loss tensor([56.7080], grad_fn=<AddBackward0>)\n",
      "Epoch 320 : Loss tensor([56.6724], grad_fn=<AddBackward0>)\n",
      "Epoch 321 : Loss tensor([56.6367], grad_fn=<AddBackward0>)\n",
      "Epoch 322 : Loss tensor([56.6010], grad_fn=<AddBackward0>)\n",
      "Epoch 323 : Loss tensor([56.5651], grad_fn=<AddBackward0>)\n",
      "Epoch 324 : Loss tensor([56.5292], grad_fn=<AddBackward0>)\n",
      "Epoch 325 : Loss tensor([56.4931], grad_fn=<AddBackward0>)\n",
      "Epoch 326 : Loss tensor([56.4570], grad_fn=<AddBackward0>)\n",
      "Epoch 327 : Loss tensor([56.4207], grad_fn=<AddBackward0>)\n",
      "Epoch 328 : Loss tensor([56.3844], grad_fn=<AddBackward0>)\n",
      "Epoch 329 : Loss tensor([56.3479], grad_fn=<AddBackward0>)\n",
      "Epoch 330 : Loss tensor([56.3114], grad_fn=<AddBackward0>)\n",
      "Epoch 331 : Loss tensor([56.2748], grad_fn=<AddBackward0>)\n",
      "Epoch 332 : Loss tensor([56.2381], grad_fn=<AddBackward0>)\n",
      "Epoch 333 : Loss tensor([56.2013], grad_fn=<AddBackward0>)\n",
      "Epoch 334 : Loss tensor([56.1644], grad_fn=<AddBackward0>)\n",
      "Epoch 335 : Loss tensor([56.1274], grad_fn=<AddBackward0>)\n",
      "Epoch 336 : Loss tensor([56.0903], grad_fn=<AddBackward0>)\n",
      "Epoch 337 : Loss tensor([56.0532], grad_fn=<AddBackward0>)\n",
      "Epoch 338 : Loss tensor([56.0159], grad_fn=<AddBackward0>)\n",
      "Epoch 339 : Loss tensor([55.9785], grad_fn=<AddBackward0>)\n",
      "Epoch 340 : Loss tensor([55.9411], grad_fn=<AddBackward0>)\n",
      "Epoch 341 : Loss tensor([55.9035], grad_fn=<AddBackward0>)\n",
      "Epoch 342 : Loss tensor([55.8659], grad_fn=<AddBackward0>)\n",
      "Epoch 343 : Loss tensor([55.8281], grad_fn=<AddBackward0>)\n",
      "Epoch 344 : Loss tensor([55.7903], grad_fn=<AddBackward0>)\n",
      "Epoch 345 : Loss tensor([55.7524], grad_fn=<AddBackward0>)\n",
      "Epoch 346 : Loss tensor([55.7144], grad_fn=<AddBackward0>)\n",
      "Epoch 347 : Loss tensor([55.6763], grad_fn=<AddBackward0>)\n",
      "Epoch 348 : Loss tensor([55.6381], grad_fn=<AddBackward0>)\n",
      "Epoch 349 : Loss tensor([55.5998], grad_fn=<AddBackward0>)\n",
      "Epoch 350 : Loss tensor([55.5614], grad_fn=<AddBackward0>)\n",
      "Epoch 351 : Loss tensor([55.5229], grad_fn=<AddBackward0>)\n",
      "Epoch 352 : Loss tensor([55.4844], grad_fn=<AddBackward0>)\n",
      "Epoch 353 : Loss tensor([55.4457], grad_fn=<AddBackward0>)\n",
      "Epoch 354 : Loss tensor([55.4070], grad_fn=<AddBackward0>)\n",
      "Epoch 355 : Loss tensor([55.3682], grad_fn=<AddBackward0>)\n",
      "Epoch 356 : Loss tensor([55.3292], grad_fn=<AddBackward0>)\n",
      "Epoch 357 : Loss tensor([55.2902], grad_fn=<AddBackward0>)\n",
      "Epoch 358 : Loss tensor([55.2511], grad_fn=<AddBackward0>)\n",
      "Epoch 359 : Loss tensor([55.2120], grad_fn=<AddBackward0>)\n",
      "Epoch 360 : Loss tensor([55.1727], grad_fn=<AddBackward0>)\n",
      "Epoch 361 : Loss tensor([55.1333], grad_fn=<AddBackward0>)\n",
      "Epoch 362 : Loss tensor([55.0938], grad_fn=<AddBackward0>)\n",
      "Epoch 363 : Loss tensor([55.0543], grad_fn=<AddBackward0>)\n",
      "Epoch 364 : Loss tensor([55.0146], grad_fn=<AddBackward0>)\n",
      "Epoch 365 : Loss tensor([54.9749], grad_fn=<AddBackward0>)\n",
      "Epoch 366 : Loss tensor([54.9351], grad_fn=<AddBackward0>)\n",
      "Epoch 367 : Loss tensor([54.8952], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368 : Loss tensor([54.8552], grad_fn=<AddBackward0>)\n",
      "Epoch 369 : Loss tensor([54.8151], grad_fn=<AddBackward0>)\n",
      "Epoch 370 : Loss tensor([54.7749], grad_fn=<AddBackward0>)\n",
      "Epoch 371 : Loss tensor([54.7347], grad_fn=<AddBackward0>)\n",
      "Epoch 372 : Loss tensor([54.6943], grad_fn=<AddBackward0>)\n",
      "Epoch 373 : Loss tensor([54.6539], grad_fn=<AddBackward0>)\n",
      "Epoch 374 : Loss tensor([54.6134], grad_fn=<AddBackward0>)\n",
      "Epoch 375 : Loss tensor([54.5728], grad_fn=<AddBackward0>)\n",
      "Epoch 376 : Loss tensor([54.5321], grad_fn=<AddBackward0>)\n",
      "Epoch 377 : Loss tensor([54.4913], grad_fn=<AddBackward0>)\n",
      "Epoch 378 : Loss tensor([54.4504], grad_fn=<AddBackward0>)\n",
      "Epoch 379 : Loss tensor([54.4095], grad_fn=<AddBackward0>)\n",
      "Epoch 380 : Loss tensor([54.3684], grad_fn=<AddBackward0>)\n",
      "Epoch 381 : Loss tensor([54.3273], grad_fn=<AddBackward0>)\n",
      "Epoch 382 : Loss tensor([54.2861], grad_fn=<AddBackward0>)\n",
      "Epoch 383 : Loss tensor([54.2448], grad_fn=<AddBackward0>)\n",
      "Epoch 384 : Loss tensor([54.2034], grad_fn=<AddBackward0>)\n",
      "Epoch 385 : Loss tensor([54.1619], grad_fn=<AddBackward0>)\n",
      "Epoch 386 : Loss tensor([54.1204], grad_fn=<AddBackward0>)\n",
      "Epoch 387 : Loss tensor([54.0787], grad_fn=<AddBackward0>)\n",
      "Epoch 388 : Loss tensor([54.0370], grad_fn=<AddBackward0>)\n",
      "Epoch 389 : Loss tensor([53.9952], grad_fn=<AddBackward0>)\n",
      "Epoch 390 : Loss tensor([53.9533], grad_fn=<AddBackward0>)\n",
      "Epoch 391 : Loss tensor([53.9113], grad_fn=<AddBackward0>)\n",
      "Epoch 392 : Loss tensor([53.8692], grad_fn=<AddBackward0>)\n",
      "Epoch 393 : Loss tensor([53.8271], grad_fn=<AddBackward0>)\n",
      "Epoch 394 : Loss tensor([53.7848], grad_fn=<AddBackward0>)\n",
      "Epoch 395 : Loss tensor([53.7425], grad_fn=<AddBackward0>)\n",
      "Epoch 396 : Loss tensor([53.7001], grad_fn=<AddBackward0>)\n",
      "Epoch 397 : Loss tensor([53.6576], grad_fn=<AddBackward0>)\n",
      "Epoch 398 : Loss tensor([53.6151], grad_fn=<AddBackward0>)\n",
      "Epoch 399 : Loss tensor([53.5724], grad_fn=<AddBackward0>)\n",
      "Epoch 400 : Loss tensor([53.5296], grad_fn=<AddBackward0>)\n",
      "Epoch 401 : Loss tensor([53.4868], grad_fn=<AddBackward0>)\n",
      "Epoch 402 : Loss tensor([53.4439], grad_fn=<AddBackward0>)\n",
      "Epoch 403 : Loss tensor([53.4009], grad_fn=<AddBackward0>)\n",
      "Epoch 404 : Loss tensor([53.3579], grad_fn=<AddBackward0>)\n",
      "Epoch 405 : Loss tensor([53.3147], grad_fn=<AddBackward0>)\n",
      "Epoch 406 : Loss tensor([53.2715], grad_fn=<AddBackward0>)\n",
      "Epoch 407 : Loss tensor([53.2282], grad_fn=<AddBackward0>)\n",
      "Epoch 408 : Loss tensor([53.1848], grad_fn=<AddBackward0>)\n",
      "Epoch 409 : Loss tensor([53.1413], grad_fn=<AddBackward0>)\n",
      "Epoch 410 : Loss tensor([53.0977], grad_fn=<AddBackward0>)\n",
      "Epoch 411 : Loss tensor([53.0541], grad_fn=<AddBackward0>)\n",
      "Epoch 412 : Loss tensor([53.0104], grad_fn=<AddBackward0>)\n",
      "Epoch 413 : Loss tensor([52.9665], grad_fn=<AddBackward0>)\n",
      "Epoch 414 : Loss tensor([52.9227], grad_fn=<AddBackward0>)\n",
      "Epoch 415 : Loss tensor([52.8787], grad_fn=<AddBackward0>)\n",
      "Epoch 416 : Loss tensor([52.8347], grad_fn=<AddBackward0>)\n",
      "Epoch 417 : Loss tensor([52.7905], grad_fn=<AddBackward0>)\n",
      "Epoch 418 : Loss tensor([52.7463], grad_fn=<AddBackward0>)\n",
      "Epoch 419 : Loss tensor([52.7020], grad_fn=<AddBackward0>)\n",
      "Epoch 420 : Loss tensor([52.6577], grad_fn=<AddBackward0>)\n",
      "Epoch 421 : Loss tensor([52.6132], grad_fn=<AddBackward0>)\n",
      "Epoch 422 : Loss tensor([52.5687], grad_fn=<AddBackward0>)\n",
      "Epoch 423 : Loss tensor([52.5241], grad_fn=<AddBackward0>)\n",
      "Epoch 424 : Loss tensor([52.4794], grad_fn=<AddBackward0>)\n",
      "Epoch 425 : Loss tensor([52.4346], grad_fn=<AddBackward0>)\n",
      "Epoch 426 : Loss tensor([52.3898], grad_fn=<AddBackward0>)\n",
      "Epoch 427 : Loss tensor([52.3449], grad_fn=<AddBackward0>)\n",
      "Epoch 428 : Loss tensor([52.2999], grad_fn=<AddBackward0>)\n",
      "Epoch 429 : Loss tensor([52.2548], grad_fn=<AddBackward0>)\n",
      "Epoch 430 : Loss tensor([52.2096], grad_fn=<AddBackward0>)\n",
      "Epoch 431 : Loss tensor([52.1644], grad_fn=<AddBackward0>)\n",
      "Epoch 432 : Loss tensor([52.1191], grad_fn=<AddBackward0>)\n",
      "Epoch 433 : Loss tensor([52.0737], grad_fn=<AddBackward0>)\n",
      "Epoch 434 : Loss tensor([52.0282], grad_fn=<AddBackward0>)\n",
      "Epoch 435 : Loss tensor([51.9827], grad_fn=<AddBackward0>)\n",
      "Epoch 436 : Loss tensor([51.9371], grad_fn=<AddBackward0>)\n",
      "Epoch 437 : Loss tensor([51.8914], grad_fn=<AddBackward0>)\n",
      "Epoch 438 : Loss tensor([51.8456], grad_fn=<AddBackward0>)\n",
      "Epoch 439 : Loss tensor([51.7997], grad_fn=<AddBackward0>)\n",
      "Epoch 440 : Loss tensor([51.7538], grad_fn=<AddBackward0>)\n",
      "Epoch 441 : Loss tensor([51.7078], grad_fn=<AddBackward0>)\n",
      "Epoch 442 : Loss tensor([51.6617], grad_fn=<AddBackward0>)\n",
      "Epoch 443 : Loss tensor([51.6156], grad_fn=<AddBackward0>)\n",
      "Epoch 444 : Loss tensor([51.5693], grad_fn=<AddBackward0>)\n",
      "Epoch 445 : Loss tensor([51.5230], grad_fn=<AddBackward0>)\n",
      "Epoch 446 : Loss tensor([51.4766], grad_fn=<AddBackward0>)\n",
      "Epoch 447 : Loss tensor([51.4302], grad_fn=<AddBackward0>)\n",
      "Epoch 448 : Loss tensor([51.3836], grad_fn=<AddBackward0>)\n",
      "Epoch 449 : Loss tensor([51.3370], grad_fn=<AddBackward0>)\n",
      "Epoch 450 : Loss tensor([51.2904], grad_fn=<AddBackward0>)\n",
      "Epoch 451 : Loss tensor([51.2436], grad_fn=<AddBackward0>)\n",
      "Epoch 452 : Loss tensor([51.1968], grad_fn=<AddBackward0>)\n",
      "Epoch 453 : Loss tensor([51.1499], grad_fn=<AddBackward0>)\n",
      "Epoch 454 : Loss tensor([51.1029], grad_fn=<AddBackward0>)\n",
      "Epoch 455 : Loss tensor([51.0558], grad_fn=<AddBackward0>)\n",
      "Epoch 456 : Loss tensor([51.0087], grad_fn=<AddBackward0>)\n",
      "Epoch 457 : Loss tensor([50.9615], grad_fn=<AddBackward0>)\n",
      "Epoch 458 : Loss tensor([50.9143], grad_fn=<AddBackward0>)\n",
      "Epoch 459 : Loss tensor([50.8669], grad_fn=<AddBackward0>)\n",
      "Epoch 460 : Loss tensor([50.8195], grad_fn=<AddBackward0>)\n",
      "Epoch 461 : Loss tensor([50.7720], grad_fn=<AddBackward0>)\n",
      "Epoch 462 : Loss tensor([50.7244], grad_fn=<AddBackward0>)\n",
      "Epoch 463 : Loss tensor([50.6768], grad_fn=<AddBackward0>)\n",
      "Epoch 464 : Loss tensor([50.6291], grad_fn=<AddBackward0>)\n",
      "Epoch 465 : Loss tensor([50.5813], grad_fn=<AddBackward0>)\n",
      "Epoch 466 : Loss tensor([50.5335], grad_fn=<AddBackward0>)\n",
      "Epoch 467 : Loss tensor([50.4855], grad_fn=<AddBackward0>)\n",
      "Epoch 468 : Loss tensor([50.4375], grad_fn=<AddBackward0>)\n",
      "Epoch 469 : Loss tensor([50.3895], grad_fn=<AddBackward0>)\n",
      "Epoch 470 : Loss tensor([50.3413], grad_fn=<AddBackward0>)\n",
      "Epoch 471 : Loss tensor([50.2931], grad_fn=<AddBackward0>)\n",
      "Epoch 472 : Loss tensor([50.2449], grad_fn=<AddBackward0>)\n",
      "Epoch 473 : Loss tensor([50.1965], grad_fn=<AddBackward0>)\n",
      "Epoch 474 : Loss tensor([50.1481], grad_fn=<AddBackward0>)\n",
      "Epoch 475 : Loss tensor([50.0996], grad_fn=<AddBackward0>)\n",
      "Epoch 476 : Loss tensor([50.0510], grad_fn=<AddBackward0>)\n",
      "Epoch 477 : Loss tensor([50.0024], grad_fn=<AddBackward0>)\n",
      "Epoch 478 : Loss tensor([49.9537], grad_fn=<AddBackward0>)\n",
      "Epoch 479 : Loss tensor([49.9049], grad_fn=<AddBackward0>)\n",
      "Epoch 480 : Loss tensor([49.8561], grad_fn=<AddBackward0>)\n",
      "Epoch 481 : Loss tensor([49.8072], grad_fn=<AddBackward0>)\n",
      "Epoch 482 : Loss tensor([49.7582], grad_fn=<AddBackward0>)\n",
      "Epoch 483 : Loss tensor([49.7092], grad_fn=<AddBackward0>)\n",
      "Epoch 484 : Loss tensor([49.6600], grad_fn=<AddBackward0>)\n",
      "Epoch 485 : Loss tensor([49.6109], grad_fn=<AddBackward0>)\n",
      "Epoch 486 : Loss tensor([49.5616], grad_fn=<AddBackward0>)\n",
      "Epoch 487 : Loss tensor([49.5123], grad_fn=<AddBackward0>)\n",
      "Epoch 488 : Loss tensor([49.4629], grad_fn=<AddBackward0>)\n",
      "Epoch 489 : Loss tensor([49.4134], grad_fn=<AddBackward0>)\n",
      "Epoch 490 : Loss tensor([49.3639], grad_fn=<AddBackward0>)\n",
      "Epoch 491 : Loss tensor([49.3143], grad_fn=<AddBackward0>)\n",
      "Epoch 492 : Loss tensor([49.2647], grad_fn=<AddBackward0>)\n",
      "Epoch 493 : Loss tensor([49.2149], grad_fn=<AddBackward0>)\n",
      "Epoch 494 : Loss tensor([49.1651], grad_fn=<AddBackward0>)\n",
      "Epoch 495 : Loss tensor([49.1153], grad_fn=<AddBackward0>)\n",
      "Epoch 496 : Loss tensor([49.0653], grad_fn=<AddBackward0>)\n",
      "Epoch 497 : Loss tensor([49.0154], grad_fn=<AddBackward0>)\n",
      "Epoch 498 : Loss tensor([48.9653], grad_fn=<AddBackward0>)\n",
      "Epoch 499 : Loss tensor([48.9152], grad_fn=<AddBackward0>)\n",
      "Epoch 500 : Loss tensor([48.8650], grad_fn=<AddBackward0>)\n",
      "Epoch 501 : Loss tensor([48.8147], grad_fn=<AddBackward0>)\n",
      "Epoch 502 : Loss tensor([48.7644], grad_fn=<AddBackward0>)\n",
      "Epoch 503 : Loss tensor([48.7140], grad_fn=<AddBackward0>)\n",
      "Epoch 504 : Loss tensor([48.6635], grad_fn=<AddBackward0>)\n",
      "Epoch 505 : Loss tensor([48.6130], grad_fn=<AddBackward0>)\n",
      "Epoch 506 : Loss tensor([48.5624], grad_fn=<AddBackward0>)\n",
      "Epoch 507 : Loss tensor([48.5117], grad_fn=<AddBackward0>)\n",
      "Epoch 508 : Loss tensor([48.4610], grad_fn=<AddBackward0>)\n",
      "Epoch 509 : Loss tensor([48.4102], grad_fn=<AddBackward0>)\n",
      "Epoch 510 : Loss tensor([48.3594], grad_fn=<AddBackward0>)\n",
      "Epoch 511 : Loss tensor([48.3084], grad_fn=<AddBackward0>)\n",
      "Epoch 512 : Loss tensor([48.2575], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513 : Loss tensor([48.2064], grad_fn=<AddBackward0>)\n",
      "Epoch 514 : Loss tensor([48.1553], grad_fn=<AddBackward0>)\n",
      "Epoch 515 : Loss tensor([48.1041], grad_fn=<AddBackward0>)\n",
      "Epoch 516 : Loss tensor([48.0529], grad_fn=<AddBackward0>)\n",
      "Epoch 517 : Loss tensor([48.0016], grad_fn=<AddBackward0>)\n",
      "Epoch 518 : Loss tensor([47.9502], grad_fn=<AddBackward0>)\n",
      "Epoch 519 : Loss tensor([47.8987], grad_fn=<AddBackward0>)\n",
      "Epoch 520 : Loss tensor([47.8472], grad_fn=<AddBackward0>)\n",
      "Epoch 521 : Loss tensor([47.7957], grad_fn=<AddBackward0>)\n",
      "Epoch 522 : Loss tensor([47.7440], grad_fn=<AddBackward0>)\n",
      "Epoch 523 : Loss tensor([47.6923], grad_fn=<AddBackward0>)\n",
      "Epoch 524 : Loss tensor([47.6406], grad_fn=<AddBackward0>)\n",
      "Epoch 525 : Loss tensor([47.5887], grad_fn=<AddBackward0>)\n",
      "Epoch 526 : Loss tensor([47.5369], grad_fn=<AddBackward0>)\n",
      "Epoch 527 : Loss tensor([47.4849], grad_fn=<AddBackward0>)\n",
      "Epoch 528 : Loss tensor([47.4329], grad_fn=<AddBackward0>)\n",
      "Epoch 529 : Loss tensor([47.3808], grad_fn=<AddBackward0>)\n",
      "Epoch 530 : Loss tensor([47.3287], grad_fn=<AddBackward0>)\n",
      "Epoch 531 : Loss tensor([47.2764], grad_fn=<AddBackward0>)\n",
      "Epoch 532 : Loss tensor([47.2242], grad_fn=<AddBackward0>)\n",
      "Epoch 533 : Loss tensor([47.1718], grad_fn=<AddBackward0>)\n",
      "Epoch 534 : Loss tensor([47.1194], grad_fn=<AddBackward0>)\n",
      "Epoch 535 : Loss tensor([47.0669], grad_fn=<AddBackward0>)\n",
      "Epoch 536 : Loss tensor([47.0144], grad_fn=<AddBackward0>)\n",
      "Epoch 537 : Loss tensor([46.9618], grad_fn=<AddBackward0>)\n",
      "Epoch 538 : Loss tensor([46.9091], grad_fn=<AddBackward0>)\n",
      "Epoch 539 : Loss tensor([46.8564], grad_fn=<AddBackward0>)\n",
      "Epoch 540 : Loss tensor([46.8036], grad_fn=<AddBackward0>)\n",
      "Epoch 541 : Loss tensor([46.7507], grad_fn=<AddBackward0>)\n",
      "Epoch 542 : Loss tensor([46.6978], grad_fn=<AddBackward0>)\n",
      "Epoch 543 : Loss tensor([46.6448], grad_fn=<AddBackward0>)\n",
      "Epoch 544 : Loss tensor([46.5918], grad_fn=<AddBackward0>)\n",
      "Epoch 545 : Loss tensor([46.5386], grad_fn=<AddBackward0>)\n",
      "Epoch 546 : Loss tensor([46.4854], grad_fn=<AddBackward0>)\n",
      "Epoch 547 : Loss tensor([46.4322], grad_fn=<AddBackward0>)\n",
      "Epoch 548 : Loss tensor([46.3789], grad_fn=<AddBackward0>)\n",
      "Epoch 549 : Loss tensor([46.3255], grad_fn=<AddBackward0>)\n",
      "Epoch 550 : Loss tensor([46.2720], grad_fn=<AddBackward0>)\n",
      "Epoch 551 : Loss tensor([46.2185], grad_fn=<AddBackward0>)\n",
      "Epoch 552 : Loss tensor([46.1649], grad_fn=<AddBackward0>)\n",
      "Epoch 553 : Loss tensor([46.1112], grad_fn=<AddBackward0>)\n",
      "Epoch 554 : Loss tensor([46.0575], grad_fn=<AddBackward0>)\n",
      "Epoch 555 : Loss tensor([46.0037], grad_fn=<AddBackward0>)\n",
      "Epoch 556 : Loss tensor([45.9498], grad_fn=<AddBackward0>)\n",
      "Epoch 557 : Loss tensor([45.8958], grad_fn=<AddBackward0>)\n",
      "Epoch 558 : Loss tensor([45.8418], grad_fn=<AddBackward0>)\n",
      "Epoch 559 : Loss tensor([45.7877], grad_fn=<AddBackward0>)\n",
      "Epoch 560 : Loss tensor([45.7336], grad_fn=<AddBackward0>)\n",
      "Epoch 561 : Loss tensor([45.6793], grad_fn=<AddBackward0>)\n",
      "Epoch 562 : Loss tensor([45.6250], grad_fn=<AddBackward0>)\n",
      "Epoch 563 : Loss tensor([45.5706], grad_fn=<AddBackward0>)\n",
      "Epoch 564 : Loss tensor([45.5162], grad_fn=<AddBackward0>)\n",
      "Epoch 565 : Loss tensor([45.4616], grad_fn=<AddBackward0>)\n",
      "Epoch 566 : Loss tensor([45.4070], grad_fn=<AddBackward0>)\n",
      "Epoch 567 : Loss tensor([45.3523], grad_fn=<AddBackward0>)\n",
      "Epoch 568 : Loss tensor([45.2975], grad_fn=<AddBackward0>)\n",
      "Epoch 569 : Loss tensor([45.2427], grad_fn=<AddBackward0>)\n",
      "Epoch 570 : Loss tensor([45.1877], grad_fn=<AddBackward0>)\n",
      "Epoch 571 : Loss tensor([45.1327], grad_fn=<AddBackward0>)\n",
      "Epoch 572 : Loss tensor([45.0776], grad_fn=<AddBackward0>)\n",
      "Epoch 573 : Loss tensor([45.0224], grad_fn=<AddBackward0>)\n",
      "Epoch 574 : Loss tensor([44.9671], grad_fn=<AddBackward0>)\n",
      "Epoch 575 : Loss tensor([44.9117], grad_fn=<AddBackward0>)\n",
      "Epoch 576 : Loss tensor([44.8562], grad_fn=<AddBackward0>)\n",
      "Epoch 577 : Loss tensor([44.8007], grad_fn=<AddBackward0>)\n",
      "Epoch 578 : Loss tensor([44.7450], grad_fn=<AddBackward0>)\n",
      "Epoch 579 : Loss tensor([44.6893], grad_fn=<AddBackward0>)\n",
      "Epoch 580 : Loss tensor([44.6334], grad_fn=<AddBackward0>)\n",
      "Epoch 581 : Loss tensor([44.5774], grad_fn=<AddBackward0>)\n",
      "Epoch 582 : Loss tensor([44.5214], grad_fn=<AddBackward0>)\n",
      "Epoch 583 : Loss tensor([44.4652], grad_fn=<AddBackward0>)\n",
      "Epoch 584 : Loss tensor([44.4089], grad_fn=<AddBackward0>)\n",
      "Epoch 585 : Loss tensor([44.3525], grad_fn=<AddBackward0>)\n",
      "Epoch 586 : Loss tensor([44.2960], grad_fn=<AddBackward0>)\n",
      "Epoch 587 : Loss tensor([44.2393], grad_fn=<AddBackward0>)\n",
      "Epoch 588 : Loss tensor([44.1825], grad_fn=<AddBackward0>)\n",
      "Epoch 589 : Loss tensor([44.1256], grad_fn=<AddBackward0>)\n",
      "Epoch 590 : Loss tensor([44.0686], grad_fn=<AddBackward0>)\n",
      "Epoch 591 : Loss tensor([44.0114], grad_fn=<AddBackward0>)\n",
      "Epoch 592 : Loss tensor([43.9541], grad_fn=<AddBackward0>)\n",
      "Epoch 593 : Loss tensor([43.8966], grad_fn=<AddBackward0>)\n",
      "Epoch 594 : Loss tensor([43.8390], grad_fn=<AddBackward0>)\n",
      "Epoch 595 : Loss tensor([43.7812], grad_fn=<AddBackward0>)\n",
      "Epoch 596 : Loss tensor([43.7233], grad_fn=<AddBackward0>)\n",
      "Epoch 597 : Loss tensor([43.6651], grad_fn=<AddBackward0>)\n",
      "Epoch 598 : Loss tensor([43.6068], grad_fn=<AddBackward0>)\n",
      "Epoch 599 : Loss tensor([43.5484], grad_fn=<AddBackward0>)\n",
      "Epoch 600 : Loss tensor([43.4897], grad_fn=<AddBackward0>)\n",
      "Epoch 601 : Loss tensor([43.4308], grad_fn=<AddBackward0>)\n",
      "Epoch 602 : Loss tensor([43.3717], grad_fn=<AddBackward0>)\n",
      "Epoch 603 : Loss tensor([43.3124], grad_fn=<AddBackward0>)\n",
      "Epoch 604 : Loss tensor([43.2528], grad_fn=<AddBackward0>)\n",
      "Epoch 605 : Loss tensor([43.1930], grad_fn=<AddBackward0>)\n",
      "Epoch 606 : Loss tensor([43.1330], grad_fn=<AddBackward0>)\n",
      "Epoch 607 : Loss tensor([43.0727], grad_fn=<AddBackward0>)\n",
      "Epoch 608 : Loss tensor([43.0121], grad_fn=<AddBackward0>)\n",
      "Epoch 609 : Loss tensor([42.9512], grad_fn=<AddBackward0>)\n",
      "Epoch 610 : Loss tensor([42.8901], grad_fn=<AddBackward0>)\n",
      "Epoch 611 : Loss tensor([42.8286], grad_fn=<AddBackward0>)\n",
      "Epoch 612 : Loss tensor([42.7668], grad_fn=<AddBackward0>)\n",
      "Epoch 613 : Loss tensor([42.7047], grad_fn=<AddBackward0>)\n",
      "Epoch 614 : Loss tensor([42.6422], grad_fn=<AddBackward0>)\n",
      "Epoch 615 : Loss tensor([42.5793], grad_fn=<AddBackward0>)\n",
      "Epoch 616 : Loss tensor([42.5161], grad_fn=<AddBackward0>)\n",
      "Epoch 617 : Loss tensor([42.4525], grad_fn=<AddBackward0>)\n",
      "Epoch 618 : Loss tensor([42.3885], grad_fn=<AddBackward0>)\n",
      "Epoch 619 : Loss tensor([42.3241], grad_fn=<AddBackward0>)\n",
      "Epoch 620 : Loss tensor([42.2593], grad_fn=<AddBackward0>)\n",
      "Epoch 621 : Loss tensor([42.1940], grad_fn=<AddBackward0>)\n",
      "Epoch 622 : Loss tensor([42.1283], grad_fn=<AddBackward0>)\n",
      "Epoch 623 : Loss tensor([42.0622], grad_fn=<AddBackward0>)\n",
      "Epoch 624 : Loss tensor([41.9957], grad_fn=<AddBackward0>)\n",
      "Epoch 625 : Loss tensor([41.9287], grad_fn=<AddBackward0>)\n",
      "Epoch 626 : Loss tensor([41.8613], grad_fn=<AddBackward0>)\n",
      "Epoch 627 : Loss tensor([41.7935], grad_fn=<AddBackward0>)\n",
      "Epoch 628 : Loss tensor([41.7253], grad_fn=<AddBackward0>)\n",
      "Epoch 629 : Loss tensor([41.6568], grad_fn=<AddBackward0>)\n",
      "Epoch 630 : Loss tensor([41.5879], grad_fn=<AddBackward0>)\n",
      "Epoch 631 : Loss tensor([41.5188], grad_fn=<AddBackward0>)\n",
      "Epoch 632 : Loss tensor([41.4494], grad_fn=<AddBackward0>)\n",
      "Epoch 633 : Loss tensor([41.3798], grad_fn=<AddBackward0>)\n",
      "Epoch 634 : Loss tensor([41.3101], grad_fn=<AddBackward0>)\n",
      "Epoch 635 : Loss tensor([41.2403], grad_fn=<AddBackward0>)\n",
      "Epoch 636 : Loss tensor([41.1705], grad_fn=<AddBackward0>)\n",
      "Epoch 637 : Loss tensor([41.1008], grad_fn=<AddBackward0>)\n",
      "Epoch 638 : Loss tensor([41.0312], grad_fn=<AddBackward0>)\n",
      "Epoch 639 : Loss tensor([40.9619], grad_fn=<AddBackward0>)\n",
      "Epoch 640 : Loss tensor([40.8928], grad_fn=<AddBackward0>)\n",
      "Epoch 641 : Loss tensor([40.8241], grad_fn=<AddBackward0>)\n",
      "Epoch 642 : Loss tensor([40.7558], grad_fn=<AddBackward0>)\n",
      "Epoch 643 : Loss tensor([40.6880], grad_fn=<AddBackward0>)\n",
      "Epoch 644 : Loss tensor([40.6206], grad_fn=<AddBackward0>)\n",
      "Epoch 645 : Loss tensor([40.5538], grad_fn=<AddBackward0>)\n",
      "Epoch 646 : Loss tensor([40.4876], grad_fn=<AddBackward0>)\n",
      "Epoch 647 : Loss tensor([40.4219], grad_fn=<AddBackward0>)\n",
      "Epoch 648 : Loss tensor([40.3567], grad_fn=<AddBackward0>)\n",
      "Epoch 649 : Loss tensor([40.2921], grad_fn=<AddBackward0>)\n",
      "Epoch 650 : Loss tensor([40.2281], grad_fn=<AddBackward0>)\n",
      "Epoch 651 : Loss tensor([40.1645], grad_fn=<AddBackward0>)\n",
      "Epoch 652 : Loss tensor([40.1014], grad_fn=<AddBackward0>)\n",
      "Epoch 653 : Loss tensor([40.0387], grad_fn=<AddBackward0>)\n",
      "Epoch 654 : Loss tensor([39.9764], grad_fn=<AddBackward0>)\n",
      "Epoch 655 : Loss tensor([39.9144], grad_fn=<AddBackward0>)\n",
      "Epoch 656 : Loss tensor([39.8527], grad_fn=<AddBackward0>)\n",
      "Epoch 657 : Loss tensor([39.7913], grad_fn=<AddBackward0>)\n",
      "Epoch 658 : Loss tensor([39.7302], grad_fn=<AddBackward0>)\n",
      "Epoch 659 : Loss tensor([39.6692], grad_fn=<AddBackward0>)\n",
      "Epoch 660 : Loss tensor([39.6083], grad_fn=<AddBackward0>)\n",
      "Epoch 661 : Loss tensor([39.5476], grad_fn=<AddBackward0>)\n",
      "Epoch 662 : Loss tensor([39.4869], grad_fn=<AddBackward0>)\n",
      "Epoch 663 : Loss tensor([39.4264], grad_fn=<AddBackward0>)\n",
      "Epoch 664 : Loss tensor([39.3658], grad_fn=<AddBackward0>)\n",
      "Epoch 665 : Loss tensor([39.3053], grad_fn=<AddBackward0>)\n",
      "Epoch 666 : Loss tensor([39.2447], grad_fn=<AddBackward0>)\n",
      "Epoch 667 : Loss tensor([39.1842], grad_fn=<AddBackward0>)\n",
      "Epoch 668 : Loss tensor([39.1236], grad_fn=<AddBackward0>)\n",
      "Epoch 669 : Loss tensor([39.0629], grad_fn=<AddBackward0>)\n",
      "Epoch 670 : Loss tensor([39.0022], grad_fn=<AddBackward0>)\n",
      "Epoch 671 : Loss tensor([38.9414], grad_fn=<AddBackward0>)\n",
      "Epoch 672 : Loss tensor([38.8805], grad_fn=<AddBackward0>)\n",
      "Epoch 673 : Loss tensor([38.8195], grad_fn=<AddBackward0>)\n",
      "Epoch 674 : Loss tensor([38.7584], grad_fn=<AddBackward0>)\n",
      "Epoch 675 : Loss tensor([38.6971], grad_fn=<AddBackward0>)\n",
      "Epoch 676 : Loss tensor([38.6358], grad_fn=<AddBackward0>)\n",
      "Epoch 677 : Loss tensor([38.5743], grad_fn=<AddBackward0>)\n",
      "Epoch 678 : Loss tensor([38.5126], grad_fn=<AddBackward0>)\n",
      "Epoch 679 : Loss tensor([38.4508], grad_fn=<AddBackward0>)\n",
      "Epoch 680 : Loss tensor([38.3888], grad_fn=<AddBackward0>)\n",
      "Epoch 681 : Loss tensor([38.3267], grad_fn=<AddBackward0>)\n",
      "Epoch 682 : Loss tensor([38.2643], grad_fn=<AddBackward0>)\n",
      "Epoch 683 : Loss tensor([38.2018], grad_fn=<AddBackward0>)\n",
      "Epoch 684 : Loss tensor([38.1391], grad_fn=<AddBackward0>)\n",
      "Epoch 685 : Loss tensor([38.0761], grad_fn=<AddBackward0>)\n",
      "Epoch 686 : Loss tensor([38.0130], grad_fn=<AddBackward0>)\n",
      "Epoch 687 : Loss tensor([37.9496], grad_fn=<AddBackward0>)\n",
      "Epoch 688 : Loss tensor([37.8860], grad_fn=<AddBackward0>)\n",
      "Epoch 689 : Loss tensor([37.8221], grad_fn=<AddBackward0>)\n",
      "Epoch 690 : Loss tensor([37.7580], grad_fn=<AddBackward0>)\n",
      "Epoch 691 : Loss tensor([37.6936], grad_fn=<AddBackward0>)\n",
      "Epoch 692 : Loss tensor([37.6289], grad_fn=<AddBackward0>)\n",
      "Epoch 693 : Loss tensor([37.5639], grad_fn=<AddBackward0>)\n",
      "Epoch 694 : Loss tensor([37.4987], grad_fn=<AddBackward0>)\n",
      "Epoch 695 : Loss tensor([37.4331], grad_fn=<AddBackward0>)\n",
      "Epoch 696 : Loss tensor([37.3672], grad_fn=<AddBackward0>)\n",
      "Epoch 697 : Loss tensor([37.3011], grad_fn=<AddBackward0>)\n",
      "Epoch 698 : Loss tensor([37.2345], grad_fn=<AddBackward0>)\n",
      "Epoch 699 : Loss tensor([37.1677], grad_fn=<AddBackward0>)\n",
      "Epoch 700 : Loss tensor([37.1005], grad_fn=<AddBackward0>)\n",
      "Epoch 701 : Loss tensor([37.0330], grad_fn=<AddBackward0>)\n",
      "Epoch 702 : Loss tensor([36.9652], grad_fn=<AddBackward0>)\n",
      "Epoch 703 : Loss tensor([36.8970], grad_fn=<AddBackward0>)\n",
      "Epoch 704 : Loss tensor([36.8285], grad_fn=<AddBackward0>)\n",
      "Epoch 705 : Loss tensor([36.7597], grad_fn=<AddBackward0>)\n",
      "Epoch 706 : Loss tensor([36.6907], grad_fn=<AddBackward0>)\n",
      "Epoch 707 : Loss tensor([36.6213], grad_fn=<AddBackward0>)\n",
      "Epoch 708 : Loss tensor([36.5517], grad_fn=<AddBackward0>)\n",
      "Epoch 709 : Loss tensor([36.4820], grad_fn=<AddBackward0>)\n",
      "Epoch 710 : Loss tensor([36.4120], grad_fn=<AddBackward0>)\n",
      "Epoch 711 : Loss tensor([36.3419], grad_fn=<AddBackward0>)\n",
      "Epoch 712 : Loss tensor([36.2716], grad_fn=<AddBackward0>)\n",
      "Epoch 713 : Loss tensor([36.2014], grad_fn=<AddBackward0>)\n",
      "Epoch 714 : Loss tensor([36.1311], grad_fn=<AddBackward0>)\n",
      "Epoch 715 : Loss tensor([36.0609], grad_fn=<AddBackward0>)\n",
      "Epoch 716 : Loss tensor([35.9908], grad_fn=<AddBackward0>)\n",
      "Epoch 717 : Loss tensor([35.9209], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 718 : Loss tensor([35.8513], grad_fn=<AddBackward0>)\n",
      "Epoch 719 : Loss tensor([35.7818], grad_fn=<AddBackward0>)\n",
      "Epoch 720 : Loss tensor([35.7128], grad_fn=<AddBackward0>)\n",
      "Epoch 721 : Loss tensor([35.6441], grad_fn=<AddBackward0>)\n",
      "Epoch 722 : Loss tensor([35.5758], grad_fn=<AddBackward0>)\n",
      "Epoch 723 : Loss tensor([35.5079], grad_fn=<AddBackward0>)\n",
      "Epoch 724 : Loss tensor([35.4406], grad_fn=<AddBackward0>)\n",
      "Epoch 725 : Loss tensor([35.3737], grad_fn=<AddBackward0>)\n",
      "Epoch 726 : Loss tensor([35.3074], grad_fn=<AddBackward0>)\n",
      "Epoch 727 : Loss tensor([35.2415], grad_fn=<AddBackward0>)\n",
      "Epoch 728 : Loss tensor([35.1761], grad_fn=<AddBackward0>)\n",
      "Epoch 729 : Loss tensor([35.1113], grad_fn=<AddBackward0>)\n",
      "Epoch 730 : Loss tensor([35.0469], grad_fn=<AddBackward0>)\n",
      "Epoch 731 : Loss tensor([34.9830], grad_fn=<AddBackward0>)\n",
      "Epoch 732 : Loss tensor([34.9195], grad_fn=<AddBackward0>)\n",
      "Epoch 733 : Loss tensor([34.8563], grad_fn=<AddBackward0>)\n",
      "Epoch 734 : Loss tensor([34.7936], grad_fn=<AddBackward0>)\n",
      "Epoch 735 : Loss tensor([34.7312], grad_fn=<AddBackward0>)\n",
      "Epoch 736 : Loss tensor([34.6692], grad_fn=<AddBackward0>)\n",
      "Epoch 737 : Loss tensor([34.6074], grad_fn=<AddBackward0>)\n",
      "Epoch 738 : Loss tensor([34.5458], grad_fn=<AddBackward0>)\n",
      "Epoch 739 : Loss tensor([34.4845], grad_fn=<AddBackward0>)\n",
      "Epoch 740 : Loss tensor([34.4234], grad_fn=<AddBackward0>)\n",
      "Epoch 741 : Loss tensor([34.3624], grad_fn=<AddBackward0>)\n",
      "Epoch 742 : Loss tensor([34.3016], grad_fn=<AddBackward0>)\n",
      "Epoch 743 : Loss tensor([34.2410], grad_fn=<AddBackward0>)\n",
      "Epoch 744 : Loss tensor([34.1804], grad_fn=<AddBackward0>)\n",
      "Epoch 745 : Loss tensor([34.1200], grad_fn=<AddBackward0>)\n",
      "Epoch 746 : Loss tensor([34.0596], grad_fn=<AddBackward0>)\n",
      "Epoch 747 : Loss tensor([33.9993], grad_fn=<AddBackward0>)\n",
      "Epoch 748 : Loss tensor([33.9391], grad_fn=<AddBackward0>)\n",
      "Epoch 749 : Loss tensor([33.8790], grad_fn=<AddBackward0>)\n",
      "Epoch 750 : Loss tensor([33.8188], grad_fn=<AddBackward0>)\n",
      "Epoch 751 : Loss tensor([33.7587], grad_fn=<AddBackward0>)\n",
      "Epoch 752 : Loss tensor([33.6987], grad_fn=<AddBackward0>)\n",
      "Epoch 753 : Loss tensor([33.6386], grad_fn=<AddBackward0>)\n",
      "Epoch 754 : Loss tensor([33.5786], grad_fn=<AddBackward0>)\n",
      "Epoch 755 : Loss tensor([33.5186], grad_fn=<AddBackward0>)\n",
      "Epoch 756 : Loss tensor([33.4586], grad_fn=<AddBackward0>)\n",
      "Epoch 757 : Loss tensor([33.3987], grad_fn=<AddBackward0>)\n",
      "Epoch 758 : Loss tensor([33.3387], grad_fn=<AddBackward0>)\n",
      "Epoch 759 : Loss tensor([33.2787], grad_fn=<AddBackward0>)\n",
      "Epoch 760 : Loss tensor([33.2188], grad_fn=<AddBackward0>)\n",
      "Epoch 761 : Loss tensor([33.1588], grad_fn=<AddBackward0>)\n",
      "Epoch 762 : Loss tensor([33.0989], grad_fn=<AddBackward0>)\n",
      "Epoch 763 : Loss tensor([33.0390], grad_fn=<AddBackward0>)\n",
      "Epoch 764 : Loss tensor([32.9790], grad_fn=<AddBackward0>)\n",
      "Epoch 765 : Loss tensor([32.9191], grad_fn=<AddBackward0>)\n",
      "Epoch 766 : Loss tensor([32.8592], grad_fn=<AddBackward0>)\n",
      "Epoch 767 : Loss tensor([32.7992], grad_fn=<AddBackward0>)\n",
      "Epoch 768 : Loss tensor([32.7393], grad_fn=<AddBackward0>)\n",
      "Epoch 769 : Loss tensor([32.6794], grad_fn=<AddBackward0>)\n",
      "Epoch 770 : Loss tensor([32.6195], grad_fn=<AddBackward0>)\n",
      "Epoch 771 : Loss tensor([32.5595], grad_fn=<AddBackward0>)\n",
      "Epoch 772 : Loss tensor([32.4996], grad_fn=<AddBackward0>)\n",
      "Epoch 773 : Loss tensor([32.4397], grad_fn=<AddBackward0>)\n",
      "Epoch 774 : Loss tensor([32.3798], grad_fn=<AddBackward0>)\n",
      "Epoch 775 : Loss tensor([32.3199], grad_fn=<AddBackward0>)\n",
      "Epoch 776 : Loss tensor([32.2599], grad_fn=<AddBackward0>)\n",
      "Epoch 777 : Loss tensor([32.2000], grad_fn=<AddBackward0>)\n",
      "Epoch 778 : Loss tensor([32.1401], grad_fn=<AddBackward0>)\n",
      "Epoch 779 : Loss tensor([32.0802], grad_fn=<AddBackward0>)\n",
      "Epoch 780 : Loss tensor([32.0203], grad_fn=<AddBackward0>)\n",
      "Epoch 781 : Loss tensor([31.9605], grad_fn=<AddBackward0>)\n",
      "Epoch 782 : Loss tensor([31.9006], grad_fn=<AddBackward0>)\n",
      "Epoch 783 : Loss tensor([31.8407], grad_fn=<AddBackward0>)\n",
      "Epoch 784 : Loss tensor([31.7808], grad_fn=<AddBackward0>)\n",
      "Epoch 785 : Loss tensor([31.7210], grad_fn=<AddBackward0>)\n",
      "Epoch 786 : Loss tensor([31.6611], grad_fn=<AddBackward0>)\n",
      "Epoch 787 : Loss tensor([31.6013], grad_fn=<AddBackward0>)\n",
      "Epoch 788 : Loss tensor([31.5414], grad_fn=<AddBackward0>)\n",
      "Epoch 789 : Loss tensor([31.4816], grad_fn=<AddBackward0>)\n",
      "Epoch 790 : Loss tensor([31.4218], grad_fn=<AddBackward0>)\n",
      "Epoch 791 : Loss tensor([31.3620], grad_fn=<AddBackward0>)\n",
      "Epoch 792 : Loss tensor([31.3022], grad_fn=<AddBackward0>)\n",
      "Epoch 793 : Loss tensor([31.2424], grad_fn=<AddBackward0>)\n",
      "Epoch 794 : Loss tensor([31.1827], grad_fn=<AddBackward0>)\n",
      "Epoch 795 : Loss tensor([31.1229], grad_fn=<AddBackward0>)\n",
      "Epoch 796 : Loss tensor([31.0632], grad_fn=<AddBackward0>)\n",
      "Epoch 797 : Loss tensor([31.0035], grad_fn=<AddBackward0>)\n",
      "Epoch 798 : Loss tensor([30.9438], grad_fn=<AddBackward0>)\n",
      "Epoch 799 : Loss tensor([30.8841], grad_fn=<AddBackward0>)\n",
      "Epoch 800 : Loss tensor([30.8245], grad_fn=<AddBackward0>)\n",
      "Epoch 801 : Loss tensor([30.7649], grad_fn=<AddBackward0>)\n",
      "Epoch 802 : Loss tensor([30.7053], grad_fn=<AddBackward0>)\n",
      "Epoch 803 : Loss tensor([30.6457], grad_fn=<AddBackward0>)\n",
      "Epoch 804 : Loss tensor([30.5862], grad_fn=<AddBackward0>)\n",
      "Epoch 805 : Loss tensor([30.5267], grad_fn=<AddBackward0>)\n",
      "Epoch 806 : Loss tensor([30.4672], grad_fn=<AddBackward0>)\n",
      "Epoch 807 : Loss tensor([30.4077], grad_fn=<AddBackward0>)\n",
      "Epoch 808 : Loss tensor([30.3483], grad_fn=<AddBackward0>)\n",
      "Epoch 809 : Loss tensor([30.2889], grad_fn=<AddBackward0>)\n",
      "Epoch 810 : Loss tensor([30.2296], grad_fn=<AddBackward0>)\n",
      "Epoch 811 : Loss tensor([30.1703], grad_fn=<AddBackward0>)\n",
      "Epoch 812 : Loss tensor([30.1110], grad_fn=<AddBackward0>)\n",
      "Epoch 813 : Loss tensor([30.0518], grad_fn=<AddBackward0>)\n",
      "Epoch 814 : Loss tensor([29.9926], grad_fn=<AddBackward0>)\n",
      "Epoch 815 : Loss tensor([29.9335], grad_fn=<AddBackward0>)\n",
      "Epoch 816 : Loss tensor([29.8744], grad_fn=<AddBackward0>)\n",
      "Epoch 817 : Loss tensor([29.8154], grad_fn=<AddBackward0>)\n",
      "Epoch 818 : Loss tensor([29.7564], grad_fn=<AddBackward0>)\n",
      "Epoch 819 : Loss tensor([29.6975], grad_fn=<AddBackward0>)\n",
      "Epoch 820 : Loss tensor([29.6386], grad_fn=<AddBackward0>)\n",
      "Epoch 821 : Loss tensor([29.5798], grad_fn=<AddBackward0>)\n",
      "Epoch 822 : Loss tensor([29.5211], grad_fn=<AddBackward0>)\n",
      "Epoch 823 : Loss tensor([29.4624], grad_fn=<AddBackward0>)\n",
      "Epoch 824 : Loss tensor([29.4038], grad_fn=<AddBackward0>)\n",
      "Epoch 825 : Loss tensor([29.3453], grad_fn=<AddBackward0>)\n",
      "Epoch 826 : Loss tensor([29.2868], grad_fn=<AddBackward0>)\n",
      "Epoch 827 : Loss tensor([29.2284], grad_fn=<AddBackward0>)\n",
      "Epoch 828 : Loss tensor([29.1700], grad_fn=<AddBackward0>)\n",
      "Epoch 829 : Loss tensor([29.1118], grad_fn=<AddBackward0>)\n",
      "Epoch 830 : Loss tensor([29.0536], grad_fn=<AddBackward0>)\n",
      "Epoch 831 : Loss tensor([28.9954], grad_fn=<AddBackward0>)\n",
      "Epoch 832 : Loss tensor([28.9374], grad_fn=<AddBackward0>)\n",
      "Epoch 833 : Loss tensor([28.8794], grad_fn=<AddBackward0>)\n",
      "Epoch 834 : Loss tensor([28.8215], grad_fn=<AddBackward0>)\n",
      "Epoch 835 : Loss tensor([28.7637], grad_fn=<AddBackward0>)\n",
      "Epoch 836 : Loss tensor([28.7059], grad_fn=<AddBackward0>)\n",
      "Epoch 837 : Loss tensor([28.6482], grad_fn=<AddBackward0>)\n",
      "Epoch 838 : Loss tensor([28.5906], grad_fn=<AddBackward0>)\n",
      "Epoch 839 : Loss tensor([28.5330], grad_fn=<AddBackward0>)\n",
      "Epoch 840 : Loss tensor([28.4755], grad_fn=<AddBackward0>)\n",
      "Epoch 841 : Loss tensor([28.4181], grad_fn=<AddBackward0>)\n",
      "Epoch 842 : Loss tensor([28.3607], grad_fn=<AddBackward0>)\n",
      "Epoch 843 : Loss tensor([28.3034], grad_fn=<AddBackward0>)\n",
      "Epoch 844 : Loss tensor([28.2461], grad_fn=<AddBackward0>)\n",
      "Epoch 845 : Loss tensor([28.1889], grad_fn=<AddBackward0>)\n",
      "Epoch 846 : Loss tensor([28.1317], grad_fn=<AddBackward0>)\n",
      "Epoch 847 : Loss tensor([28.0746], grad_fn=<AddBackward0>)\n",
      "Epoch 848 : Loss tensor([28.0175], grad_fn=<AddBackward0>)\n",
      "Epoch 849 : Loss tensor([27.9604], grad_fn=<AddBackward0>)\n",
      "Epoch 850 : Loss tensor([27.9034], grad_fn=<AddBackward0>)\n",
      "Epoch 851 : Loss tensor([27.8464], grad_fn=<AddBackward0>)\n",
      "Epoch 852 : Loss tensor([27.7894], grad_fn=<AddBackward0>)\n",
      "Epoch 853 : Loss tensor([27.7324], grad_fn=<AddBackward0>)\n",
      "Epoch 854 : Loss tensor([27.6755], grad_fn=<AddBackward0>)\n",
      "Epoch 855 : Loss tensor([27.6185], grad_fn=<AddBackward0>)\n",
      "Epoch 856 : Loss tensor([27.5616], grad_fn=<AddBackward0>)\n",
      "Epoch 857 : Loss tensor([27.5046], grad_fn=<AddBackward0>)\n",
      "Epoch 858 : Loss tensor([27.4476], grad_fn=<AddBackward0>)\n",
      "Epoch 859 : Loss tensor([27.3906], grad_fn=<AddBackward0>)\n",
      "Epoch 860 : Loss tensor([27.3336], grad_fn=<AddBackward0>)\n",
      "Epoch 861 : Loss tensor([27.2765], grad_fn=<AddBackward0>)\n",
      "Epoch 862 : Loss tensor([27.2194], grad_fn=<AddBackward0>)\n",
      "Epoch 863 : Loss tensor([27.1623], grad_fn=<AddBackward0>)\n",
      "Epoch 864 : Loss tensor([27.1051], grad_fn=<AddBackward0>)\n",
      "Epoch 865 : Loss tensor([27.0478], grad_fn=<AddBackward0>)\n",
      "Epoch 866 : Loss tensor([26.9906], grad_fn=<AddBackward0>)\n",
      "Epoch 867 : Loss tensor([26.9332], grad_fn=<AddBackward0>)\n",
      "Epoch 868 : Loss tensor([26.8758], grad_fn=<AddBackward0>)\n",
      "Epoch 869 : Loss tensor([26.8183], grad_fn=<AddBackward0>)\n",
      "Epoch 870 : Loss tensor([26.7608], grad_fn=<AddBackward0>)\n",
      "Epoch 871 : Loss tensor([26.7032], grad_fn=<AddBackward0>)\n",
      "Epoch 872 : Loss tensor([26.6455], grad_fn=<AddBackward0>)\n",
      "Epoch 873 : Loss tensor([26.5877], grad_fn=<AddBackward0>)\n",
      "Epoch 874 : Loss tensor([26.5298], grad_fn=<AddBackward0>)\n",
      "Epoch 875 : Loss tensor([26.4718], grad_fn=<AddBackward0>)\n",
      "Epoch 876 : Loss tensor([26.4138], grad_fn=<AddBackward0>)\n",
      "Epoch 877 : Loss tensor([26.3556], grad_fn=<AddBackward0>)\n",
      "Epoch 878 : Loss tensor([26.2974], grad_fn=<AddBackward0>)\n",
      "Epoch 879 : Loss tensor([26.2391], grad_fn=<AddBackward0>)\n",
      "Epoch 880 : Loss tensor([26.1806], grad_fn=<AddBackward0>)\n",
      "Epoch 881 : Loss tensor([26.1221], grad_fn=<AddBackward0>)\n",
      "Epoch 882 : Loss tensor([26.0634], grad_fn=<AddBackward0>)\n",
      "Epoch 883 : Loss tensor([26.0046], grad_fn=<AddBackward0>)\n",
      "Epoch 884 : Loss tensor([25.9458], grad_fn=<AddBackward0>)\n",
      "Epoch 885 : Loss tensor([25.8868], grad_fn=<AddBackward0>)\n",
      "Epoch 886 : Loss tensor([25.8277], grad_fn=<AddBackward0>)\n",
      "Epoch 887 : Loss tensor([25.7685], grad_fn=<AddBackward0>)\n",
      "Epoch 888 : Loss tensor([25.7091], grad_fn=<AddBackward0>)\n",
      "Epoch 889 : Loss tensor([25.6497], grad_fn=<AddBackward0>)\n",
      "Epoch 890 : Loss tensor([25.5901], grad_fn=<AddBackward0>)\n",
      "Epoch 891 : Loss tensor([25.5304], grad_fn=<AddBackward0>)\n",
      "Epoch 892 : Loss tensor([25.4706], grad_fn=<AddBackward0>)\n",
      "Epoch 893 : Loss tensor([25.4107], grad_fn=<AddBackward0>)\n",
      "Epoch 894 : Loss tensor([25.3507], grad_fn=<AddBackward0>)\n",
      "Epoch 895 : Loss tensor([25.2905], grad_fn=<AddBackward0>)\n",
      "Epoch 896 : Loss tensor([25.2302], grad_fn=<AddBackward0>)\n",
      "Epoch 897 : Loss tensor([25.1698], grad_fn=<AddBackward0>)\n",
      "Epoch 898 : Loss tensor([25.1093], grad_fn=<AddBackward0>)\n",
      "Epoch 899 : Loss tensor([25.0486], grad_fn=<AddBackward0>)\n",
      "Epoch 900 : Loss tensor([24.9878], grad_fn=<AddBackward0>)\n",
      "Epoch 901 : Loss tensor([24.9269], grad_fn=<AddBackward0>)\n",
      "Epoch 902 : Loss tensor([24.8659], grad_fn=<AddBackward0>)\n",
      "Epoch 903 : Loss tensor([24.8047], grad_fn=<AddBackward0>)\n",
      "Epoch 904 : Loss tensor([24.7434], grad_fn=<AddBackward0>)\n",
      "Epoch 905 : Loss tensor([24.6820], grad_fn=<AddBackward0>)\n",
      "Epoch 906 : Loss tensor([24.6204], grad_fn=<AddBackward0>)\n",
      "Epoch 907 : Loss tensor([24.5588], grad_fn=<AddBackward0>)\n",
      "Epoch 908 : Loss tensor([24.4970], grad_fn=<AddBackward0>)\n",
      "Epoch 909 : Loss tensor([24.4350], grad_fn=<AddBackward0>)\n",
      "Epoch 910 : Loss tensor([24.3730], grad_fn=<AddBackward0>)\n",
      "Epoch 911 : Loss tensor([24.3108], grad_fn=<AddBackward0>)\n",
      "Epoch 912 : Loss tensor([24.2484], grad_fn=<AddBackward0>)\n",
      "Epoch 913 : Loss tensor([24.1860], grad_fn=<AddBackward0>)\n",
      "Epoch 914 : Loss tensor([24.1234], grad_fn=<AddBackward0>)\n",
      "Epoch 915 : Loss tensor([24.0607], grad_fn=<AddBackward0>)\n",
      "Epoch 916 : Loss tensor([23.9978], grad_fn=<AddBackward0>)\n",
      "Epoch 917 : Loss tensor([23.9347], grad_fn=<AddBackward0>)\n",
      "Epoch 918 : Loss tensor([23.8716], grad_fn=<AddBackward0>)\n",
      "Epoch 919 : Loss tensor([23.8082], grad_fn=<AddBackward0>)\n",
      "Epoch 920 : Loss tensor([23.7448], grad_fn=<AddBackward0>)\n",
      "Epoch 921 : Loss tensor([23.6811], grad_fn=<AddBackward0>)\n",
      "Epoch 922 : Loss tensor([23.6173], grad_fn=<AddBackward0>)\n",
      "Epoch 923 : Loss tensor([23.5533], grad_fn=<AddBackward0>)\n",
      "Epoch 924 : Loss tensor([23.4891], grad_fn=<AddBackward0>)\n",
      "Epoch 925 : Loss tensor([23.4248], grad_fn=<AddBackward0>)\n",
      "Epoch 926 : Loss tensor([23.3602], grad_fn=<AddBackward0>)\n",
      "Epoch 927 : Loss tensor([23.2955], grad_fn=<AddBackward0>)\n",
      "Epoch 928 : Loss tensor([23.2305], grad_fn=<AddBackward0>)\n",
      "Epoch 929 : Loss tensor([23.1653], grad_fn=<AddBackward0>)\n",
      "Epoch 930 : Loss tensor([23.0999], grad_fn=<AddBackward0>)\n",
      "Epoch 931 : Loss tensor([23.0342], grad_fn=<AddBackward0>)\n",
      "Epoch 932 : Loss tensor([22.9683], grad_fn=<AddBackward0>)\n",
      "Epoch 933 : Loss tensor([22.9021], grad_fn=<AddBackward0>)\n",
      "Epoch 934 : Loss tensor([22.8357], grad_fn=<AddBackward0>)\n",
      "Epoch 935 : Loss tensor([22.7691], grad_fn=<AddBackward0>)\n",
      "Epoch 936 : Loss tensor([22.7021], grad_fn=<AddBackward0>)\n",
      "Epoch 937 : Loss tensor([22.6349], grad_fn=<AddBackward0>)\n",
      "Epoch 938 : Loss tensor([22.5674], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939 : Loss tensor([22.4997], grad_fn=<AddBackward0>)\n",
      "Epoch 940 : Loss tensor([22.4317], grad_fn=<AddBackward0>)\n",
      "Epoch 941 : Loss tensor([22.3635], grad_fn=<AddBackward0>)\n",
      "Epoch 942 : Loss tensor([22.2950], grad_fn=<AddBackward0>)\n",
      "Epoch 943 : Loss tensor([22.2264], grad_fn=<AddBackward0>)\n",
      "Epoch 944 : Loss tensor([22.1576], grad_fn=<AddBackward0>)\n",
      "Epoch 945 : Loss tensor([22.0887], grad_fn=<AddBackward0>)\n",
      "Epoch 946 : Loss tensor([22.0196], grad_fn=<AddBackward0>)\n",
      "Epoch 947 : Loss tensor([21.9506], grad_fn=<AddBackward0>)\n",
      "Epoch 948 : Loss tensor([21.8816], grad_fn=<AddBackward0>)\n",
      "Epoch 949 : Loss tensor([21.8126], grad_fn=<AddBackward0>)\n",
      "Epoch 950 : Loss tensor([21.7438], grad_fn=<AddBackward0>)\n",
      "Epoch 951 : Loss tensor([21.6752], grad_fn=<AddBackward0>)\n",
      "Epoch 952 : Loss tensor([21.6068], grad_fn=<AddBackward0>)\n",
      "Epoch 953 : Loss tensor([21.5389], grad_fn=<AddBackward0>)\n",
      "Epoch 954 : Loss tensor([21.4713], grad_fn=<AddBackward0>)\n",
      "Epoch 955 : Loss tensor([21.4042], grad_fn=<AddBackward0>)\n",
      "Epoch 956 : Loss tensor([21.3376], grad_fn=<AddBackward0>)\n",
      "Epoch 957 : Loss tensor([21.2717], grad_fn=<AddBackward0>)\n",
      "Epoch 958 : Loss tensor([21.2063], grad_fn=<AddBackward0>)\n",
      "Epoch 959 : Loss tensor([21.1416], grad_fn=<AddBackward0>)\n",
      "Epoch 960 : Loss tensor([21.0776], grad_fn=<AddBackward0>)\n",
      "Epoch 961 : Loss tensor([21.0143], grad_fn=<AddBackward0>)\n",
      "Epoch 962 : Loss tensor([20.9516], grad_fn=<AddBackward0>)\n",
      "Epoch 963 : Loss tensor([20.8896], grad_fn=<AddBackward0>)\n",
      "Epoch 964 : Loss tensor([20.8283], grad_fn=<AddBackward0>)\n",
      "Epoch 965 : Loss tensor([20.7676], grad_fn=<AddBackward0>)\n",
      "Epoch 966 : Loss tensor([20.7075], grad_fn=<AddBackward0>)\n",
      "Epoch 967 : Loss tensor([20.6480], grad_fn=<AddBackward0>)\n",
      "Epoch 968 : Loss tensor([20.5890], grad_fn=<AddBackward0>)\n",
      "Epoch 969 : Loss tensor([20.5305], grad_fn=<AddBackward0>)\n",
      "Epoch 970 : Loss tensor([20.4725], grad_fn=<AddBackward0>)\n",
      "Epoch 971 : Loss tensor([20.4148], grad_fn=<AddBackward0>)\n",
      "Epoch 972 : Loss tensor([20.3576], grad_fn=<AddBackward0>)\n",
      "Epoch 973 : Loss tensor([20.3006], grad_fn=<AddBackward0>)\n",
      "Epoch 974 : Loss tensor([20.2440], grad_fn=<AddBackward0>)\n",
      "Epoch 975 : Loss tensor([20.1876], grad_fn=<AddBackward0>)\n",
      "Epoch 976 : Loss tensor([20.1315], grad_fn=<AddBackward0>)\n",
      "Epoch 977 : Loss tensor([20.0756], grad_fn=<AddBackward0>)\n",
      "Epoch 978 : Loss tensor([20.0199], grad_fn=<AddBackward0>)\n",
      "Epoch 979 : Loss tensor([19.9644], grad_fn=<AddBackward0>)\n",
      "Epoch 980 : Loss tensor([19.9091], grad_fn=<AddBackward0>)\n",
      "Epoch 981 : Loss tensor([19.8538], grad_fn=<AddBackward0>)\n",
      "Epoch 982 : Loss tensor([19.7988], grad_fn=<AddBackward0>)\n",
      "Epoch 983 : Loss tensor([19.7438], grad_fn=<AddBackward0>)\n",
      "Epoch 984 : Loss tensor([19.6889], grad_fn=<AddBackward0>)\n",
      "Epoch 985 : Loss tensor([19.6342], grad_fn=<AddBackward0>)\n",
      "Epoch 986 : Loss tensor([19.5795], grad_fn=<AddBackward0>)\n",
      "Epoch 987 : Loss tensor([19.5249], grad_fn=<AddBackward0>)\n",
      "Epoch 988 : Loss tensor([19.4704], grad_fn=<AddBackward0>)\n",
      "Epoch 989 : Loss tensor([19.4160], grad_fn=<AddBackward0>)\n",
      "Epoch 990 : Loss tensor([19.3617], grad_fn=<AddBackward0>)\n",
      "Epoch 991 : Loss tensor([19.3074], grad_fn=<AddBackward0>)\n",
      "Epoch 992 : Loss tensor([19.2532], grad_fn=<AddBackward0>)\n",
      "Epoch 993 : Loss tensor([19.1990], grad_fn=<AddBackward0>)\n",
      "Epoch 994 : Loss tensor([19.1449], grad_fn=<AddBackward0>)\n",
      "Epoch 995 : Loss tensor([19.0909], grad_fn=<AddBackward0>)\n",
      "Epoch 996 : Loss tensor([19.0370], grad_fn=<AddBackward0>)\n",
      "Epoch 997 : Loss tensor([18.9831], grad_fn=<AddBackward0>)\n",
      "Epoch 998 : Loss tensor([18.9292], grad_fn=<AddBackward0>)\n",
      "Epoch 999 : Loss tensor([18.8755], grad_fn=<AddBackward0>)\n",
      "Epoch 1000 : Loss tensor([18.8217], grad_fn=<AddBackward0>)\n",
      "Epoch 1001 : Loss tensor([18.7681], grad_fn=<AddBackward0>)\n",
      "Epoch 1002 : Loss tensor([18.7145], grad_fn=<AddBackward0>)\n",
      "Epoch 1003 : Loss tensor([18.6609], grad_fn=<AddBackward0>)\n",
      "Epoch 1004 : Loss tensor([18.6074], grad_fn=<AddBackward0>)\n",
      "Epoch 1005 : Loss tensor([18.5540], grad_fn=<AddBackward0>)\n",
      "Epoch 1006 : Loss tensor([18.5006], grad_fn=<AddBackward0>)\n",
      "Epoch 1007 : Loss tensor([18.4473], grad_fn=<AddBackward0>)\n",
      "Epoch 1008 : Loss tensor([18.3940], grad_fn=<AddBackward0>)\n",
      "Epoch 1009 : Loss tensor([18.3408], grad_fn=<AddBackward0>)\n",
      "Epoch 1010 : Loss tensor([18.2876], grad_fn=<AddBackward0>)\n",
      "Epoch 1011 : Loss tensor([18.2345], grad_fn=<AddBackward0>)\n",
      "Epoch 1012 : Loss tensor([18.1815], grad_fn=<AddBackward0>)\n",
      "Epoch 1013 : Loss tensor([18.1285], grad_fn=<AddBackward0>)\n",
      "Epoch 1014 : Loss tensor([18.0756], grad_fn=<AddBackward0>)\n",
      "Epoch 1015 : Loss tensor([18.0227], grad_fn=<AddBackward0>)\n",
      "Epoch 1016 : Loss tensor([17.9699], grad_fn=<AddBackward0>)\n",
      "Epoch 1017 : Loss tensor([17.9172], grad_fn=<AddBackward0>)\n",
      "Epoch 1018 : Loss tensor([17.8645], grad_fn=<AddBackward0>)\n",
      "Epoch 1019 : Loss tensor([17.8118], grad_fn=<AddBackward0>)\n",
      "Epoch 1020 : Loss tensor([17.7592], grad_fn=<AddBackward0>)\n",
      "Epoch 1021 : Loss tensor([17.7067], grad_fn=<AddBackward0>)\n",
      "Epoch 1022 : Loss tensor([17.6542], grad_fn=<AddBackward0>)\n",
      "Epoch 1023 : Loss tensor([17.6018], grad_fn=<AddBackward0>)\n",
      "Epoch 1024 : Loss tensor([17.5495], grad_fn=<AddBackward0>)\n",
      "Epoch 1025 : Loss tensor([17.4972], grad_fn=<AddBackward0>)\n",
      "Epoch 1026 : Loss tensor([17.4449], grad_fn=<AddBackward0>)\n",
      "Epoch 1027 : Loss tensor([17.3927], grad_fn=<AddBackward0>)\n",
      "Epoch 1028 : Loss tensor([17.3406], grad_fn=<AddBackward0>)\n",
      "Epoch 1029 : Loss tensor([17.2886], grad_fn=<AddBackward0>)\n",
      "Epoch 1030 : Loss tensor([17.2366], grad_fn=<AddBackward0>)\n",
      "Epoch 1031 : Loss tensor([17.1846], grad_fn=<AddBackward0>)\n",
      "Epoch 1032 : Loss tensor([17.1327], grad_fn=<AddBackward0>)\n",
      "Epoch 1033 : Loss tensor([17.0809], grad_fn=<AddBackward0>)\n",
      "Epoch 1034 : Loss tensor([17.0292], grad_fn=<AddBackward0>)\n",
      "Epoch 1035 : Loss tensor([16.9775], grad_fn=<AddBackward0>)\n",
      "Epoch 1036 : Loss tensor([16.9258], grad_fn=<AddBackward0>)\n",
      "Epoch 1037 : Loss tensor([16.8742], grad_fn=<AddBackward0>)\n",
      "Epoch 1038 : Loss tensor([16.8227], grad_fn=<AddBackward0>)\n",
      "Epoch 1039 : Loss tensor([16.7713], grad_fn=<AddBackward0>)\n",
      "Epoch 1040 : Loss tensor([16.7199], grad_fn=<AddBackward0>)\n",
      "Epoch 1041 : Loss tensor([16.6685], grad_fn=<AddBackward0>)\n",
      "Epoch 1042 : Loss tensor([16.6173], grad_fn=<AddBackward0>)\n",
      "Epoch 1043 : Loss tensor([16.5660], grad_fn=<AddBackward0>)\n",
      "Epoch 1044 : Loss tensor([16.5149], grad_fn=<AddBackward0>)\n",
      "Epoch 1045 : Loss tensor([16.4638], grad_fn=<AddBackward0>)\n",
      "Epoch 1046 : Loss tensor([16.4128], grad_fn=<AddBackward0>)\n",
      "Epoch 1047 : Loss tensor([16.3618], grad_fn=<AddBackward0>)\n",
      "Epoch 1048 : Loss tensor([16.3109], grad_fn=<AddBackward0>)\n",
      "Epoch 1049 : Loss tensor([16.2601], grad_fn=<AddBackward0>)\n",
      "Epoch 1050 : Loss tensor([16.2093], grad_fn=<AddBackward0>)\n",
      "Epoch 1051 : Loss tensor([16.1586], grad_fn=<AddBackward0>)\n",
      "Epoch 1052 : Loss tensor([16.1079], grad_fn=<AddBackward0>)\n",
      "Epoch 1053 : Loss tensor([16.0574], grad_fn=<AddBackward0>)\n",
      "Epoch 1054 : Loss tensor([16.0068], grad_fn=<AddBackward0>)\n",
      "Epoch 1055 : Loss tensor([15.9564], grad_fn=<AddBackward0>)\n",
      "Epoch 1056 : Loss tensor([15.9060], grad_fn=<AddBackward0>)\n",
      "Epoch 1057 : Loss tensor([15.8557], grad_fn=<AddBackward0>)\n",
      "Epoch 1058 : Loss tensor([15.8054], grad_fn=<AddBackward0>)\n",
      "Epoch 1059 : Loss tensor([15.7552], grad_fn=<AddBackward0>)\n",
      "Epoch 1060 : Loss tensor([15.7051], grad_fn=<AddBackward0>)\n",
      "Epoch 1061 : Loss tensor([15.6550], grad_fn=<AddBackward0>)\n",
      "Epoch 1062 : Loss tensor([15.6050], grad_fn=<AddBackward0>)\n",
      "Epoch 1063 : Loss tensor([15.5551], grad_fn=<AddBackward0>)\n",
      "Epoch 1064 : Loss tensor([15.5052], grad_fn=<AddBackward0>)\n",
      "Epoch 1065 : Loss tensor([15.4554], grad_fn=<AddBackward0>)\n",
      "Epoch 1066 : Loss tensor([15.4057], grad_fn=<AddBackward0>)\n",
      "Epoch 1067 : Loss tensor([15.3560], grad_fn=<AddBackward0>)\n",
      "Epoch 1068 : Loss tensor([15.3064], grad_fn=<AddBackward0>)\n",
      "Epoch 1069 : Loss tensor([15.2569], grad_fn=<AddBackward0>)\n",
      "Epoch 1070 : Loss tensor([15.2074], grad_fn=<AddBackward0>)\n",
      "Epoch 1071 : Loss tensor([15.1580], grad_fn=<AddBackward0>)\n",
      "Epoch 1072 : Loss tensor([15.1086], grad_fn=<AddBackward0>)\n",
      "Epoch 1073 : Loss tensor([15.0594], grad_fn=<AddBackward0>)\n",
      "Epoch 1074 : Loss tensor([15.0102], grad_fn=<AddBackward0>)\n",
      "Epoch 1075 : Loss tensor([14.9611], grad_fn=<AddBackward0>)\n",
      "Epoch 1076 : Loss tensor([14.9120], grad_fn=<AddBackward0>)\n",
      "Epoch 1077 : Loss tensor([14.8630], grad_fn=<AddBackward0>)\n",
      "Epoch 1078 : Loss tensor([14.8141], grad_fn=<AddBackward0>)\n",
      "Epoch 1079 : Loss tensor([14.7652], grad_fn=<AddBackward0>)\n",
      "Epoch 1080 : Loss tensor([14.7164], grad_fn=<AddBackward0>)\n",
      "Epoch 1081 : Loss tensor([14.6677], grad_fn=<AddBackward0>)\n",
      "Epoch 1082 : Loss tensor([14.6191], grad_fn=<AddBackward0>)\n",
      "Epoch 1083 : Loss tensor([14.5705], grad_fn=<AddBackward0>)\n",
      "Epoch 1084 : Loss tensor([14.5220], grad_fn=<AddBackward0>)\n",
      "Epoch 1085 : Loss tensor([14.4735], grad_fn=<AddBackward0>)\n",
      "Epoch 1086 : Loss tensor([14.4252], grad_fn=<AddBackward0>)\n",
      "Epoch 1087 : Loss tensor([14.3769], grad_fn=<AddBackward0>)\n",
      "Epoch 1088 : Loss tensor([14.3286], grad_fn=<AddBackward0>)\n",
      "Epoch 1089 : Loss tensor([14.2805], grad_fn=<AddBackward0>)\n",
      "Epoch 1090 : Loss tensor([14.2324], grad_fn=<AddBackward0>)\n",
      "Epoch 1091 : Loss tensor([14.1844], grad_fn=<AddBackward0>)\n",
      "Epoch 1092 : Loss tensor([14.1364], grad_fn=<AddBackward0>)\n",
      "Epoch 1093 : Loss tensor([14.0886], grad_fn=<AddBackward0>)\n",
      "Epoch 1094 : Loss tensor([14.0408], grad_fn=<AddBackward0>)\n",
      "Epoch 1095 : Loss tensor([13.9930], grad_fn=<AddBackward0>)\n",
      "Epoch 1096 : Loss tensor([13.9454], grad_fn=<AddBackward0>)\n",
      "Epoch 1097 : Loss tensor([13.8978], grad_fn=<AddBackward0>)\n",
      "Epoch 1098 : Loss tensor([13.8503], grad_fn=<AddBackward0>)\n",
      "Epoch 1099 : Loss tensor([13.8029], grad_fn=<AddBackward0>)\n",
      "Epoch 1100 : Loss tensor([13.7555], grad_fn=<AddBackward0>)\n",
      "Epoch 1101 : Loss tensor([13.7082], grad_fn=<AddBackward0>)\n",
      "Epoch 1102 : Loss tensor([13.6610], grad_fn=<AddBackward0>)\n",
      "Epoch 1103 : Loss tensor([13.6138], grad_fn=<AddBackward0>)\n",
      "Epoch 1104 : Loss tensor([13.5668], grad_fn=<AddBackward0>)\n",
      "Epoch 1105 : Loss tensor([13.5198], grad_fn=<AddBackward0>)\n",
      "Epoch 1106 : Loss tensor([13.4728], grad_fn=<AddBackward0>)\n",
      "Epoch 1107 : Loss tensor([13.4260], grad_fn=<AddBackward0>)\n",
      "Epoch 1108 : Loss tensor([13.3792], grad_fn=<AddBackward0>)\n",
      "Epoch 1109 : Loss tensor([13.3325], grad_fn=<AddBackward0>)\n",
      "Epoch 1110 : Loss tensor([13.2859], grad_fn=<AddBackward0>)\n",
      "Epoch 1111 : Loss tensor([13.2394], grad_fn=<AddBackward0>)\n",
      "Epoch 1112 : Loss tensor([13.1929], grad_fn=<AddBackward0>)\n",
      "Epoch 1113 : Loss tensor([13.1465], grad_fn=<AddBackward0>)\n",
      "Epoch 1114 : Loss tensor([13.1002], grad_fn=<AddBackward0>)\n",
      "Epoch 1115 : Loss tensor([13.0539], grad_fn=<AddBackward0>)\n",
      "Epoch 1116 : Loss tensor([13.0077], grad_fn=<AddBackward0>)\n",
      "Epoch 1117 : Loss tensor([12.9616], grad_fn=<AddBackward0>)\n",
      "Epoch 1118 : Loss tensor([12.9156], grad_fn=<AddBackward0>)\n",
      "Epoch 1119 : Loss tensor([12.8697], grad_fn=<AddBackward0>)\n",
      "Epoch 1120 : Loss tensor([12.8238], grad_fn=<AddBackward0>)\n",
      "Epoch 1121 : Loss tensor([12.7780], grad_fn=<AddBackward0>)\n",
      "Epoch 1122 : Loss tensor([12.7323], grad_fn=<AddBackward0>)\n",
      "Epoch 1123 : Loss tensor([12.6867], grad_fn=<AddBackward0>)\n",
      "Epoch 1124 : Loss tensor([12.6411], grad_fn=<AddBackward0>)\n",
      "Epoch 1125 : Loss tensor([12.5956], grad_fn=<AddBackward0>)\n",
      "Epoch 1126 : Loss tensor([12.5502], grad_fn=<AddBackward0>)\n",
      "Epoch 1127 : Loss tensor([12.5049], grad_fn=<AddBackward0>)\n",
      "Epoch 1128 : Loss tensor([12.4597], grad_fn=<AddBackward0>)\n",
      "Epoch 1129 : Loss tensor([12.4145], grad_fn=<AddBackward0>)\n",
      "Epoch 1130 : Loss tensor([12.3694], grad_fn=<AddBackward0>)\n",
      "Epoch 1131 : Loss tensor([12.3244], grad_fn=<AddBackward0>)\n",
      "Epoch 1132 : Loss tensor([12.2795], grad_fn=<AddBackward0>)\n",
      "Epoch 1133 : Loss tensor([12.2346], grad_fn=<AddBackward0>)\n",
      "Epoch 1134 : Loss tensor([12.1899], grad_fn=<AddBackward0>)\n",
      "Epoch 1135 : Loss tensor([12.1452], grad_fn=<AddBackward0>)\n",
      "Epoch 1136 : Loss tensor([12.1005], grad_fn=<AddBackward0>)\n",
      "Epoch 1137 : Loss tensor([12.0560], grad_fn=<AddBackward0>)\n",
      "Epoch 1138 : Loss tensor([12.0116], grad_fn=<AddBackward0>)\n",
      "Epoch 1139 : Loss tensor([11.9672], grad_fn=<AddBackward0>)\n",
      "Epoch 1140 : Loss tensor([11.9229], grad_fn=<AddBackward0>)\n",
      "Epoch 1141 : Loss tensor([11.8787], grad_fn=<AddBackward0>)\n",
      "Epoch 1142 : Loss tensor([11.8346], grad_fn=<AddBackward0>)\n",
      "Epoch 1143 : Loss tensor([11.7905], grad_fn=<AddBackward0>)\n",
      "Epoch 1144 : Loss tensor([11.7465], grad_fn=<AddBackward0>)\n",
      "Epoch 1145 : Loss tensor([11.7027], grad_fn=<AddBackward0>)\n",
      "Epoch 1146 : Loss tensor([11.6588], grad_fn=<AddBackward0>)\n",
      "Epoch 1147 : Loss tensor([11.6151], grad_fn=<AddBackward0>)\n",
      "Epoch 1148 : Loss tensor([11.5715], grad_fn=<AddBackward0>)\n",
      "Epoch 1149 : Loss tensor([11.5279], grad_fn=<AddBackward0>)\n",
      "Epoch 1150 : Loss tensor([11.4844], grad_fn=<AddBackward0>)\n",
      "Epoch 1151 : Loss tensor([11.4411], grad_fn=<AddBackward0>)\n",
      "Epoch 1152 : Loss tensor([11.3977], grad_fn=<AddBackward0>)\n",
      "Epoch 1153 : Loss tensor([11.3545], grad_fn=<AddBackward0>)\n",
      "Epoch 1154 : Loss tensor([11.3114], grad_fn=<AddBackward0>)\n",
      "Epoch 1155 : Loss tensor([11.2683], grad_fn=<AddBackward0>)\n",
      "Epoch 1156 : Loss tensor([11.2253], grad_fn=<AddBackward0>)\n",
      "Epoch 1157 : Loss tensor([11.1824], grad_fn=<AddBackward0>)\n",
      "Epoch 1158 : Loss tensor([11.1396], grad_fn=<AddBackward0>)\n",
      "Epoch 1159 : Loss tensor([11.0969], grad_fn=<AddBackward0>)\n",
      "Epoch 1160 : Loss tensor([11.0543], grad_fn=<AddBackward0>)\n",
      "Epoch 1161 : Loss tensor([11.0117], grad_fn=<AddBackward0>)\n",
      "Epoch 1162 : Loss tensor([10.9692], grad_fn=<AddBackward0>)\n",
      "Epoch 1163 : Loss tensor([10.9268], grad_fn=<AddBackward0>)\n",
      "Epoch 1164 : Loss tensor([10.8845], grad_fn=<AddBackward0>)\n",
      "Epoch 1165 : Loss tensor([10.8423], grad_fn=<AddBackward0>)\n",
      "Epoch 1166 : Loss tensor([10.8002], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1167 : Loss tensor([10.7582], grad_fn=<AddBackward0>)\n",
      "Epoch 1168 : Loss tensor([10.7162], grad_fn=<AddBackward0>)\n",
      "Epoch 1169 : Loss tensor([10.6743], grad_fn=<AddBackward0>)\n",
      "Epoch 1170 : Loss tensor([10.6326], grad_fn=<AddBackward0>)\n",
      "Epoch 1171 : Loss tensor([10.5909], grad_fn=<AddBackward0>)\n",
      "Epoch 1172 : Loss tensor([10.5493], grad_fn=<AddBackward0>)\n",
      "Epoch 1173 : Loss tensor([10.5077], grad_fn=<AddBackward0>)\n",
      "Epoch 1174 : Loss tensor([10.4663], grad_fn=<AddBackward0>)\n",
      "Epoch 1175 : Loss tensor([10.4250], grad_fn=<AddBackward0>)\n",
      "Epoch 1176 : Loss tensor([10.3837], grad_fn=<AddBackward0>)\n",
      "Epoch 1177 : Loss tensor([10.3425], grad_fn=<AddBackward0>)\n",
      "Epoch 1178 : Loss tensor([10.3015], grad_fn=<AddBackward0>)\n",
      "Epoch 1179 : Loss tensor([10.2605], grad_fn=<AddBackward0>)\n",
      "Epoch 1180 : Loss tensor([10.2196], grad_fn=<AddBackward0>)\n",
      "Epoch 1181 : Loss tensor([10.1788], grad_fn=<AddBackward0>)\n",
      "Epoch 1182 : Loss tensor([10.1381], grad_fn=<AddBackward0>)\n",
      "Epoch 1183 : Loss tensor([10.0975], grad_fn=<AddBackward0>)\n",
      "Epoch 1184 : Loss tensor([10.0569], grad_fn=<AddBackward0>)\n",
      "Epoch 1185 : Loss tensor([10.0165], grad_fn=<AddBackward0>)\n",
      "Epoch 1186 : Loss tensor([9.9761], grad_fn=<AddBackward0>)\n",
      "Epoch 1187 : Loss tensor([9.9359], grad_fn=<AddBackward0>)\n",
      "Epoch 1188 : Loss tensor([9.8957], grad_fn=<AddBackward0>)\n",
      "Epoch 1189 : Loss tensor([9.8557], grad_fn=<AddBackward0>)\n",
      "Epoch 1190 : Loss tensor([9.8157], grad_fn=<AddBackward0>)\n",
      "Epoch 1191 : Loss tensor([9.7758], grad_fn=<AddBackward0>)\n",
      "Epoch 1192 : Loss tensor([9.7360], grad_fn=<AddBackward0>)\n",
      "Epoch 1193 : Loss tensor([9.6964], grad_fn=<AddBackward0>)\n",
      "Epoch 1194 : Loss tensor([9.6568], grad_fn=<AddBackward0>)\n",
      "Epoch 1195 : Loss tensor([9.6173], grad_fn=<AddBackward0>)\n",
      "Epoch 1196 : Loss tensor([9.5779], grad_fn=<AddBackward0>)\n",
      "Epoch 1197 : Loss tensor([9.5386], grad_fn=<AddBackward0>)\n",
      "Epoch 1198 : Loss tensor([9.4994], grad_fn=<AddBackward0>)\n",
      "Epoch 1199 : Loss tensor([9.4603], grad_fn=<AddBackward0>)\n",
      "Epoch 1200 : Loss tensor([9.4213], grad_fn=<AddBackward0>)\n",
      "Epoch 1201 : Loss tensor([9.3825], grad_fn=<AddBackward0>)\n",
      "Epoch 1202 : Loss tensor([9.3437], grad_fn=<AddBackward0>)\n",
      "Epoch 1203 : Loss tensor([9.3050], grad_fn=<AddBackward0>)\n",
      "Epoch 1204 : Loss tensor([9.2664], grad_fn=<AddBackward0>)\n",
      "Epoch 1205 : Loss tensor([9.2279], grad_fn=<AddBackward0>)\n",
      "Epoch 1206 : Loss tensor([9.1896], grad_fn=<AddBackward0>)\n",
      "Epoch 1207 : Loss tensor([9.1513], grad_fn=<AddBackward0>)\n",
      "Epoch 1208 : Loss tensor([9.1132], grad_fn=<AddBackward0>)\n",
      "Epoch 1209 : Loss tensor([9.0751], grad_fn=<AddBackward0>)\n",
      "Epoch 1210 : Loss tensor([9.0372], grad_fn=<AddBackward0>)\n",
      "Epoch 1211 : Loss tensor([8.9994], grad_fn=<AddBackward0>)\n",
      "Epoch 1212 : Loss tensor([8.9617], grad_fn=<AddBackward0>)\n",
      "Epoch 1213 : Loss tensor([8.9241], grad_fn=<AddBackward0>)\n",
      "Epoch 1214 : Loss tensor([8.8866], grad_fn=<AddBackward0>)\n",
      "Epoch 1215 : Loss tensor([8.8492], grad_fn=<AddBackward0>)\n",
      "Epoch 1216 : Loss tensor([8.8120], grad_fn=<AddBackward0>)\n",
      "Epoch 1217 : Loss tensor([8.7749], grad_fn=<AddBackward0>)\n",
      "Epoch 1218 : Loss tensor([8.7379], grad_fn=<AddBackward0>)\n",
      "Epoch 1219 : Loss tensor([8.7010], grad_fn=<AddBackward0>)\n",
      "Epoch 1220 : Loss tensor([8.6642], grad_fn=<AddBackward0>)\n",
      "Epoch 1221 : Loss tensor([8.6276], grad_fn=<AddBackward0>)\n",
      "Epoch 1222 : Loss tensor([8.5911], grad_fn=<AddBackward0>)\n",
      "Epoch 1223 : Loss tensor([8.5547], grad_fn=<AddBackward0>)\n",
      "Epoch 1224 : Loss tensor([8.5184], grad_fn=<AddBackward0>)\n",
      "Epoch 1225 : Loss tensor([8.4823], grad_fn=<AddBackward0>)\n",
      "Epoch 1226 : Loss tensor([8.4463], grad_fn=<AddBackward0>)\n",
      "Epoch 1227 : Loss tensor([8.4104], grad_fn=<AddBackward0>)\n",
      "Epoch 1228 : Loss tensor([8.3747], grad_fn=<AddBackward0>)\n",
      "Epoch 1229 : Loss tensor([8.3391], grad_fn=<AddBackward0>)\n",
      "Epoch 1230 : Loss tensor([8.3036], grad_fn=<AddBackward0>)\n",
      "Epoch 1231 : Loss tensor([8.2683], grad_fn=<AddBackward0>)\n",
      "Epoch 1232 : Loss tensor([8.2331], grad_fn=<AddBackward0>)\n",
      "Epoch 1233 : Loss tensor([8.1980], grad_fn=<AddBackward0>)\n",
      "Epoch 1234 : Loss tensor([8.1631], grad_fn=<AddBackward0>)\n",
      "Epoch 1235 : Loss tensor([8.1283], grad_fn=<AddBackward0>)\n",
      "Epoch 1236 : Loss tensor([8.0937], grad_fn=<AddBackward0>)\n",
      "Epoch 1237 : Loss tensor([8.0592], grad_fn=<AddBackward0>)\n",
      "Epoch 1238 : Loss tensor([8.0248], grad_fn=<AddBackward0>)\n",
      "Epoch 1239 : Loss tensor([7.9905], grad_fn=<AddBackward0>)\n",
      "Epoch 1240 : Loss tensor([7.9564], grad_fn=<AddBackward0>)\n",
      "Epoch 1241 : Loss tensor([7.9225], grad_fn=<AddBackward0>)\n",
      "Epoch 1242 : Loss tensor([7.8887], grad_fn=<AddBackward0>)\n",
      "Epoch 1243 : Loss tensor([7.8550], grad_fn=<AddBackward0>)\n",
      "Epoch 1244 : Loss tensor([7.8214], grad_fn=<AddBackward0>)\n",
      "Epoch 1245 : Loss tensor([7.7880], grad_fn=<AddBackward0>)\n",
      "Epoch 1246 : Loss tensor([7.7547], grad_fn=<AddBackward0>)\n",
      "Epoch 1247 : Loss tensor([7.7216], grad_fn=<AddBackward0>)\n",
      "Epoch 1248 : Loss tensor([7.6885], grad_fn=<AddBackward0>)\n",
      "Epoch 1249 : Loss tensor([7.6557], grad_fn=<AddBackward0>)\n",
      "Epoch 1250 : Loss tensor([7.6229], grad_fn=<AddBackward0>)\n",
      "Epoch 1251 : Loss tensor([7.5902], grad_fn=<AddBackward0>)\n",
      "Epoch 1252 : Loss tensor([7.5577], grad_fn=<AddBackward0>)\n",
      "Epoch 1253 : Loss tensor([7.5253], grad_fn=<AddBackward0>)\n",
      "Epoch 1254 : Loss tensor([7.4930], grad_fn=<AddBackward0>)\n",
      "Epoch 1255 : Loss tensor([7.4609], grad_fn=<AddBackward0>)\n",
      "Epoch 1256 : Loss tensor([7.4288], grad_fn=<AddBackward0>)\n",
      "Epoch 1257 : Loss tensor([7.3968], grad_fn=<AddBackward0>)\n",
      "Epoch 1258 : Loss tensor([7.3650], grad_fn=<AddBackward0>)\n",
      "Epoch 1259 : Loss tensor([7.3332], grad_fn=<AddBackward0>)\n",
      "Epoch 1260 : Loss tensor([7.3016], grad_fn=<AddBackward0>)\n",
      "Epoch 1261 : Loss tensor([7.2700], grad_fn=<AddBackward0>)\n",
      "Epoch 1262 : Loss tensor([7.2386], grad_fn=<AddBackward0>)\n",
      "Epoch 1263 : Loss tensor([7.2072], grad_fn=<AddBackward0>)\n",
      "Epoch 1264 : Loss tensor([7.1759], grad_fn=<AddBackward0>)\n",
      "Epoch 1265 : Loss tensor([7.1447], grad_fn=<AddBackward0>)\n",
      "Epoch 1266 : Loss tensor([7.1135], grad_fn=<AddBackward0>)\n",
      "Epoch 1267 : Loss tensor([7.0825], grad_fn=<AddBackward0>)\n",
      "Epoch 1268 : Loss tensor([7.0515], grad_fn=<AddBackward0>)\n",
      "Epoch 1269 : Loss tensor([7.0206], grad_fn=<AddBackward0>)\n",
      "Epoch 1270 : Loss tensor([6.9897], grad_fn=<AddBackward0>)\n",
      "Epoch 1271 : Loss tensor([6.9589], grad_fn=<AddBackward0>)\n",
      "Epoch 1272 : Loss tensor([6.9281], grad_fn=<AddBackward0>)\n",
      "Epoch 1273 : Loss tensor([6.8975], grad_fn=<AddBackward0>)\n",
      "Epoch 1274 : Loss tensor([6.8668], grad_fn=<AddBackward0>)\n",
      "Epoch 1275 : Loss tensor([6.8362], grad_fn=<AddBackward0>)\n",
      "Epoch 1276 : Loss tensor([6.8057], grad_fn=<AddBackward0>)\n",
      "Epoch 1277 : Loss tensor([6.7752], grad_fn=<AddBackward0>)\n",
      "Epoch 1278 : Loss tensor([6.7447], grad_fn=<AddBackward0>)\n",
      "Epoch 1279 : Loss tensor([6.7143], grad_fn=<AddBackward0>)\n",
      "Epoch 1280 : Loss tensor([6.6839], grad_fn=<AddBackward0>)\n",
      "Epoch 1281 : Loss tensor([6.6535], grad_fn=<AddBackward0>)\n",
      "Epoch 1282 : Loss tensor([6.6232], grad_fn=<AddBackward0>)\n",
      "Epoch 1283 : Loss tensor([6.5929], grad_fn=<AddBackward0>)\n",
      "Epoch 1284 : Loss tensor([6.5627], grad_fn=<AddBackward0>)\n",
      "Epoch 1285 : Loss tensor([6.5324], grad_fn=<AddBackward0>)\n",
      "Epoch 1286 : Loss tensor([6.5022], grad_fn=<AddBackward0>)\n",
      "Epoch 1287 : Loss tensor([6.4720], grad_fn=<AddBackward0>)\n",
      "Epoch 1288 : Loss tensor([6.4419], grad_fn=<AddBackward0>)\n",
      "Epoch 1289 : Loss tensor([6.4117], grad_fn=<AddBackward0>)\n",
      "Epoch 1290 : Loss tensor([6.3816], grad_fn=<AddBackward0>)\n",
      "Epoch 1291 : Loss tensor([6.3515], grad_fn=<AddBackward0>)\n",
      "Epoch 1292 : Loss tensor([6.3214], grad_fn=<AddBackward0>)\n",
      "Epoch 1293 : Loss tensor([6.2914], grad_fn=<AddBackward0>)\n",
      "Epoch 1294 : Loss tensor([6.2614], grad_fn=<AddBackward0>)\n",
      "Epoch 1295 : Loss tensor([6.2314], grad_fn=<AddBackward0>)\n",
      "Epoch 1296 : Loss tensor([6.2014], grad_fn=<AddBackward0>)\n",
      "Epoch 1297 : Loss tensor([6.1714], grad_fn=<AddBackward0>)\n",
      "Epoch 1298 : Loss tensor([6.1415], grad_fn=<AddBackward0>)\n",
      "Epoch 1299 : Loss tensor([6.1116], grad_fn=<AddBackward0>)\n",
      "Epoch 1300 : Loss tensor([6.0817], grad_fn=<AddBackward0>)\n",
      "Epoch 1301 : Loss tensor([6.0519], grad_fn=<AddBackward0>)\n",
      "Epoch 1302 : Loss tensor([6.0220], grad_fn=<AddBackward0>)\n",
      "Epoch 1303 : Loss tensor([5.9922], grad_fn=<AddBackward0>)\n",
      "Epoch 1304 : Loss tensor([5.9625], grad_fn=<AddBackward0>)\n",
      "Epoch 1305 : Loss tensor([5.9328], grad_fn=<AddBackward0>)\n",
      "Epoch 1306 : Loss tensor([5.9031], grad_fn=<AddBackward0>)\n",
      "Epoch 1307 : Loss tensor([5.8734], grad_fn=<AddBackward0>)\n",
      "Epoch 1308 : Loss tensor([5.8438], grad_fn=<AddBackward0>)\n",
      "Epoch 1309 : Loss tensor([5.8142], grad_fn=<AddBackward0>)\n",
      "Epoch 1310 : Loss tensor([5.7847], grad_fn=<AddBackward0>)\n",
      "Epoch 1311 : Loss tensor([5.7553], grad_fn=<AddBackward0>)\n",
      "Epoch 1312 : Loss tensor([5.7259], grad_fn=<AddBackward0>)\n",
      "Epoch 1313 : Loss tensor([5.6965], grad_fn=<AddBackward0>)\n",
      "Epoch 1314 : Loss tensor([5.6672], grad_fn=<AddBackward0>)\n",
      "Epoch 1315 : Loss tensor([5.6380], grad_fn=<AddBackward0>)\n",
      "Epoch 1316 : Loss tensor([5.6088], grad_fn=<AddBackward0>)\n",
      "Epoch 1317 : Loss tensor([5.5797], grad_fn=<AddBackward0>)\n",
      "Epoch 1318 : Loss tensor([5.5507], grad_fn=<AddBackward0>)\n",
      "Epoch 1319 : Loss tensor([5.5217], grad_fn=<AddBackward0>)\n",
      "Epoch 1320 : Loss tensor([5.4929], grad_fn=<AddBackward0>)\n",
      "Epoch 1321 : Loss tensor([5.4641], grad_fn=<AddBackward0>)\n",
      "Epoch 1322 : Loss tensor([5.4354], grad_fn=<AddBackward0>)\n",
      "Epoch 1323 : Loss tensor([5.4068], grad_fn=<AddBackward0>)\n",
      "Epoch 1324 : Loss tensor([5.3782], grad_fn=<AddBackward0>)\n",
      "Epoch 1325 : Loss tensor([5.3498], grad_fn=<AddBackward0>)\n",
      "Epoch 1326 : Loss tensor([5.3215], grad_fn=<AddBackward0>)\n",
      "Epoch 1327 : Loss tensor([5.2933], grad_fn=<AddBackward0>)\n",
      "Epoch 1328 : Loss tensor([5.2652], grad_fn=<AddBackward0>)\n",
      "Epoch 1329 : Loss tensor([5.2373], grad_fn=<AddBackward0>)\n",
      "Epoch 1330 : Loss tensor([5.2094], grad_fn=<AddBackward0>)\n",
      "Epoch 1331 : Loss tensor([5.1816], grad_fn=<AddBackward0>)\n",
      "Epoch 1332 : Loss tensor([5.1540], grad_fn=<AddBackward0>)\n",
      "Epoch 1333 : Loss tensor([5.1265], grad_fn=<AddBackward0>)\n",
      "Epoch 1334 : Loss tensor([5.0992], grad_fn=<AddBackward0>)\n",
      "Epoch 1335 : Loss tensor([5.0719], grad_fn=<AddBackward0>)\n",
      "Epoch 1336 : Loss tensor([5.0448], grad_fn=<AddBackward0>)\n",
      "Epoch 1337 : Loss tensor([5.0179], grad_fn=<AddBackward0>)\n",
      "Epoch 1338 : Loss tensor([4.9910], grad_fn=<AddBackward0>)\n",
      "Epoch 1339 : Loss tensor([4.9644], grad_fn=<AddBackward0>)\n",
      "Epoch 1340 : Loss tensor([4.9378], grad_fn=<AddBackward0>)\n",
      "Epoch 1341 : Loss tensor([4.9114], grad_fn=<AddBackward0>)\n",
      "Epoch 1342 : Loss tensor([4.8852], grad_fn=<AddBackward0>)\n",
      "Epoch 1343 : Loss tensor([4.8591], grad_fn=<AddBackward0>)\n",
      "Epoch 1344 : Loss tensor([4.8331], grad_fn=<AddBackward0>)\n",
      "Epoch 1345 : Loss tensor([4.8073], grad_fn=<AddBackward0>)\n",
      "Epoch 1346 : Loss tensor([4.7817], grad_fn=<AddBackward0>)\n",
      "Epoch 1347 : Loss tensor([4.7562], grad_fn=<AddBackward0>)\n",
      "Epoch 1348 : Loss tensor([4.7308], grad_fn=<AddBackward0>)\n",
      "Epoch 1349 : Loss tensor([4.7056], grad_fn=<AddBackward0>)\n",
      "Epoch 1350 : Loss tensor([4.6806], grad_fn=<AddBackward0>)\n",
      "Epoch 1351 : Loss tensor([4.6557], grad_fn=<AddBackward0>)\n",
      "Epoch 1352 : Loss tensor([4.6309], grad_fn=<AddBackward0>)\n",
      "Epoch 1353 : Loss tensor([4.6063], grad_fn=<AddBackward0>)\n",
      "Epoch 1354 : Loss tensor([4.5819], grad_fn=<AddBackward0>)\n",
      "Epoch 1355 : Loss tensor([4.5576], grad_fn=<AddBackward0>)\n",
      "Epoch 1356 : Loss tensor([4.5334], grad_fn=<AddBackward0>)\n",
      "Epoch 1357 : Loss tensor([4.5094], grad_fn=<AddBackward0>)\n",
      "Epoch 1358 : Loss tensor([4.4856], grad_fn=<AddBackward0>)\n",
      "Epoch 1359 : Loss tensor([4.4619], grad_fn=<AddBackward0>)\n",
      "Epoch 1360 : Loss tensor([4.4383], grad_fn=<AddBackward0>)\n",
      "Epoch 1361 : Loss tensor([4.4149], grad_fn=<AddBackward0>)\n",
      "Epoch 1362 : Loss tensor([4.3917], grad_fn=<AddBackward0>)\n",
      "Epoch 1363 : Loss tensor([4.3685], grad_fn=<AddBackward0>)\n",
      "Epoch 1364 : Loss tensor([4.3456], grad_fn=<AddBackward0>)\n",
      "Epoch 1365 : Loss tensor([4.3227], grad_fn=<AddBackward0>)\n",
      "Epoch 1366 : Loss tensor([4.3000], grad_fn=<AddBackward0>)\n",
      "Epoch 1367 : Loss tensor([4.2775], grad_fn=<AddBackward0>)\n",
      "Epoch 1368 : Loss tensor([4.2551], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1369 : Loss tensor([4.2328], grad_fn=<AddBackward0>)\n",
      "Epoch 1370 : Loss tensor([4.2106], grad_fn=<AddBackward0>)\n",
      "Epoch 1371 : Loss tensor([4.1886], grad_fn=<AddBackward0>)\n",
      "Epoch 1372 : Loss tensor([4.1667], grad_fn=<AddBackward0>)\n",
      "Epoch 1373 : Loss tensor([4.1450], grad_fn=<AddBackward0>)\n",
      "Epoch 1374 : Loss tensor([4.1234], grad_fn=<AddBackward0>)\n",
      "Epoch 1375 : Loss tensor([4.1019], grad_fn=<AddBackward0>)\n",
      "Epoch 1376 : Loss tensor([4.0806], grad_fn=<AddBackward0>)\n",
      "Epoch 1377 : Loss tensor([4.0593], grad_fn=<AddBackward0>)\n",
      "Epoch 1378 : Loss tensor([4.0382], grad_fn=<AddBackward0>)\n",
      "Epoch 1379 : Loss tensor([4.0173], grad_fn=<AddBackward0>)\n",
      "Epoch 1380 : Loss tensor([3.9964], grad_fn=<AddBackward0>)\n",
      "Epoch 1381 : Loss tensor([3.9757], grad_fn=<AddBackward0>)\n",
      "Epoch 1382 : Loss tensor([3.9551], grad_fn=<AddBackward0>)\n",
      "Epoch 1383 : Loss tensor([3.9347], grad_fn=<AddBackward0>)\n",
      "Epoch 1384 : Loss tensor([3.9143], grad_fn=<AddBackward0>)\n",
      "Epoch 1385 : Loss tensor([3.8941], grad_fn=<AddBackward0>)\n",
      "Epoch 1386 : Loss tensor([3.8740], grad_fn=<AddBackward0>)\n",
      "Epoch 1387 : Loss tensor([3.8541], grad_fn=<AddBackward0>)\n",
      "Epoch 1388 : Loss tensor([3.8342], grad_fn=<AddBackward0>)\n",
      "Epoch 1389 : Loss tensor([3.8145], grad_fn=<AddBackward0>)\n",
      "Epoch 1390 : Loss tensor([3.7949], grad_fn=<AddBackward0>)\n",
      "Epoch 1391 : Loss tensor([3.7754], grad_fn=<AddBackward0>)\n",
      "Epoch 1392 : Loss tensor([3.7560], grad_fn=<AddBackward0>)\n",
      "Epoch 1393 : Loss tensor([3.7367], grad_fn=<AddBackward0>)\n",
      "Epoch 1394 : Loss tensor([3.7176], grad_fn=<AddBackward0>)\n",
      "Epoch 1395 : Loss tensor([3.6986], grad_fn=<AddBackward0>)\n",
      "Epoch 1396 : Loss tensor([3.6796], grad_fn=<AddBackward0>)\n",
      "Epoch 1397 : Loss tensor([3.6608], grad_fn=<AddBackward0>)\n",
      "Epoch 1398 : Loss tensor([3.6422], grad_fn=<AddBackward0>)\n",
      "Epoch 1399 : Loss tensor([3.6236], grad_fn=<AddBackward0>)\n",
      "Epoch 1400 : Loss tensor([3.6052], grad_fn=<AddBackward0>)\n",
      "Epoch 1401 : Loss tensor([3.5868], grad_fn=<AddBackward0>)\n",
      "Epoch 1402 : Loss tensor([3.5686], grad_fn=<AddBackward0>)\n",
      "Epoch 1403 : Loss tensor([3.5505], grad_fn=<AddBackward0>)\n",
      "Epoch 1404 : Loss tensor([3.5325], grad_fn=<AddBackward0>)\n",
      "Epoch 1405 : Loss tensor([3.5146], grad_fn=<AddBackward0>)\n",
      "Epoch 1406 : Loss tensor([3.4968], grad_fn=<AddBackward0>)\n",
      "Epoch 1407 : Loss tensor([3.4791], grad_fn=<AddBackward0>)\n",
      "Epoch 1408 : Loss tensor([3.4616], grad_fn=<AddBackward0>)\n",
      "Epoch 1409 : Loss tensor([3.4441], grad_fn=<AddBackward0>)\n",
      "Epoch 1410 : Loss tensor([3.4268], grad_fn=<AddBackward0>)\n",
      "Epoch 1411 : Loss tensor([3.4095], grad_fn=<AddBackward0>)\n",
      "Epoch 1412 : Loss tensor([3.3924], grad_fn=<AddBackward0>)\n",
      "Epoch 1413 : Loss tensor([3.3753], grad_fn=<AddBackward0>)\n",
      "Epoch 1414 : Loss tensor([3.3584], grad_fn=<AddBackward0>)\n",
      "Epoch 1415 : Loss tensor([3.3416], grad_fn=<AddBackward0>)\n",
      "Epoch 1416 : Loss tensor([3.3249], grad_fn=<AddBackward0>)\n",
      "Epoch 1417 : Loss tensor([3.3083], grad_fn=<AddBackward0>)\n",
      "Epoch 1418 : Loss tensor([3.2917], grad_fn=<AddBackward0>)\n",
      "Epoch 1419 : Loss tensor([3.2753], grad_fn=<AddBackward0>)\n",
      "Epoch 1420 : Loss tensor([3.2590], grad_fn=<AddBackward0>)\n",
      "Epoch 1421 : Loss tensor([3.2428], grad_fn=<AddBackward0>)\n",
      "Epoch 1422 : Loss tensor([3.2267], grad_fn=<AddBackward0>)\n",
      "Epoch 1423 : Loss tensor([3.2106], grad_fn=<AddBackward0>)\n",
      "Epoch 1424 : Loss tensor([3.1947], grad_fn=<AddBackward0>)\n",
      "Epoch 1425 : Loss tensor([3.1788], grad_fn=<AddBackward0>)\n",
      "Epoch 1426 : Loss tensor([3.1631], grad_fn=<AddBackward0>)\n",
      "Epoch 1427 : Loss tensor([3.1474], grad_fn=<AddBackward0>)\n",
      "Epoch 1428 : Loss tensor([3.1318], grad_fn=<AddBackward0>)\n",
      "Epoch 1429 : Loss tensor([3.1163], grad_fn=<AddBackward0>)\n",
      "Epoch 1430 : Loss tensor([3.1009], grad_fn=<AddBackward0>)\n",
      "Epoch 1431 : Loss tensor([3.0856], grad_fn=<AddBackward0>)\n",
      "Epoch 1432 : Loss tensor([3.0703], grad_fn=<AddBackward0>)\n",
      "Epoch 1433 : Loss tensor([3.0551], grad_fn=<AddBackward0>)\n",
      "Epoch 1434 : Loss tensor([3.0400], grad_fn=<AddBackward0>)\n",
      "Epoch 1435 : Loss tensor([3.0249], grad_fn=<AddBackward0>)\n",
      "Epoch 1436 : Loss tensor([3.0100], grad_fn=<AddBackward0>)\n",
      "Epoch 1437 : Loss tensor([2.9950], grad_fn=<AddBackward0>)\n",
      "Epoch 1438 : Loss tensor([2.9802], grad_fn=<AddBackward0>)\n",
      "Epoch 1439 : Loss tensor([2.9654], grad_fn=<AddBackward0>)\n",
      "Epoch 1440 : Loss tensor([2.9506], grad_fn=<AddBackward0>)\n",
      "Epoch 1441 : Loss tensor([2.9359], grad_fn=<AddBackward0>)\n",
      "Epoch 1442 : Loss tensor([2.9212], grad_fn=<AddBackward0>)\n",
      "Epoch 1443 : Loss tensor([2.9066], grad_fn=<AddBackward0>)\n",
      "Epoch 1444 : Loss tensor([2.8920], grad_fn=<AddBackward0>)\n",
      "Epoch 1445 : Loss tensor([2.8774], grad_fn=<AddBackward0>)\n",
      "Epoch 1446 : Loss tensor([2.8628], grad_fn=<AddBackward0>)\n",
      "Epoch 1447 : Loss tensor([2.8482], grad_fn=<AddBackward0>)\n",
      "Epoch 1448 : Loss tensor([2.8337], grad_fn=<AddBackward0>)\n",
      "Epoch 1449 : Loss tensor([2.8191], grad_fn=<AddBackward0>)\n",
      "Epoch 1450 : Loss tensor([2.8046], grad_fn=<AddBackward0>)\n",
      "Epoch 1451 : Loss tensor([2.7900], grad_fn=<AddBackward0>)\n",
      "Epoch 1452 : Loss tensor([2.7753], grad_fn=<AddBackward0>)\n",
      "Epoch 1453 : Loss tensor([2.7607], grad_fn=<AddBackward0>)\n",
      "Epoch 1454 : Loss tensor([2.7460], grad_fn=<AddBackward0>)\n",
      "Epoch 1455 : Loss tensor([2.7312], grad_fn=<AddBackward0>)\n",
      "Epoch 1456 : Loss tensor([2.7164], grad_fn=<AddBackward0>)\n",
      "Epoch 1457 : Loss tensor([2.7014], grad_fn=<AddBackward0>)\n",
      "Epoch 1458 : Loss tensor([2.6864], grad_fn=<AddBackward0>)\n",
      "Epoch 1459 : Loss tensor([2.6713], grad_fn=<AddBackward0>)\n",
      "Epoch 1460 : Loss tensor([2.6560], grad_fn=<AddBackward0>)\n",
      "Epoch 1461 : Loss tensor([2.6406], grad_fn=<AddBackward0>)\n",
      "Epoch 1462 : Loss tensor([2.6251], grad_fn=<AddBackward0>)\n",
      "Epoch 1463 : Loss tensor([2.6093], grad_fn=<AddBackward0>)\n",
      "Epoch 1464 : Loss tensor([2.5934], grad_fn=<AddBackward0>)\n",
      "Epoch 1465 : Loss tensor([2.5773], grad_fn=<AddBackward0>)\n",
      "Epoch 1466 : Loss tensor([2.5609], grad_fn=<AddBackward0>)\n",
      "Epoch 1467 : Loss tensor([2.5443], grad_fn=<AddBackward0>)\n",
      "Epoch 1468 : Loss tensor([2.5275], grad_fn=<AddBackward0>)\n",
      "Epoch 1469 : Loss tensor([2.5104], grad_fn=<AddBackward0>)\n",
      "Epoch 1470 : Loss tensor([2.4929], grad_fn=<AddBackward0>)\n",
      "Epoch 1471 : Loss tensor([2.4752], grad_fn=<AddBackward0>)\n",
      "Epoch 1472 : Loss tensor([2.4571], grad_fn=<AddBackward0>)\n",
      "Epoch 1473 : Loss tensor([2.4387], grad_fn=<AddBackward0>)\n",
      "Epoch 1474 : Loss tensor([2.4199], grad_fn=<AddBackward0>)\n",
      "Epoch 1475 : Loss tensor([2.4008], grad_fn=<AddBackward0>)\n",
      "Epoch 1476 : Loss tensor([2.3813], grad_fn=<AddBackward0>)\n",
      "Epoch 1477 : Loss tensor([2.3615], grad_fn=<AddBackward0>)\n",
      "Epoch 1478 : Loss tensor([2.3413], grad_fn=<AddBackward0>)\n",
      "Epoch 1479 : Loss tensor([2.3207], grad_fn=<AddBackward0>)\n",
      "Epoch 1480 : Loss tensor([2.2998], grad_fn=<AddBackward0>)\n",
      "Epoch 1481 : Loss tensor([2.2786], grad_fn=<AddBackward0>)\n",
      "Epoch 1482 : Loss tensor([2.2571], grad_fn=<AddBackward0>)\n",
      "Epoch 1483 : Loss tensor([2.2354], grad_fn=<AddBackward0>)\n",
      "Epoch 1484 : Loss tensor([2.2135], grad_fn=<AddBackward0>)\n",
      "Epoch 1485 : Loss tensor([2.1915], grad_fn=<AddBackward0>)\n",
      "Epoch 1486 : Loss tensor([2.1695], grad_fn=<AddBackward0>)\n",
      "Epoch 1487 : Loss tensor([2.1475], grad_fn=<AddBackward0>)\n",
      "Epoch 1488 : Loss tensor([2.1257], grad_fn=<AddBackward0>)\n",
      "Epoch 1489 : Loss tensor([2.1041], grad_fn=<AddBackward0>)\n",
      "Epoch 1490 : Loss tensor([2.0828], grad_fn=<AddBackward0>)\n",
      "Epoch 1491 : Loss tensor([2.0619], grad_fn=<AddBackward0>)\n",
      "Epoch 1492 : Loss tensor([2.0416], grad_fn=<AddBackward0>)\n",
      "Epoch 1493 : Loss tensor([2.0219], grad_fn=<AddBackward0>)\n",
      "Epoch 1494 : Loss tensor([2.0029], grad_fn=<AddBackward0>)\n",
      "Epoch 1495 : Loss tensor([1.9846], grad_fn=<AddBackward0>)\n",
      "Epoch 1496 : Loss tensor([1.9671], grad_fn=<AddBackward0>)\n",
      "Epoch 1497 : Loss tensor([1.9505], grad_fn=<AddBackward0>)\n",
      "Epoch 1498 : Loss tensor([1.9348], grad_fn=<AddBackward0>)\n",
      "Epoch 1499 : Loss tensor([1.9200], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_goal=np.array([[0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [1],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0],\n",
    "                 [0]])\n",
    "image = train(epochs=1500,\n",
    "              learning_rate=torch.tensor([0.00001]),\n",
    "              _lambda=torch.tensor([0.05]),\n",
    "              x_target=x_target.view([784,1]),\n",
    "              y_goal=torch.as_tensor(y_goal,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1650dd400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.view(28,28).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
