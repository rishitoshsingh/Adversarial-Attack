\textbf{\abstractname{:}} Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems. In recent years, artificial intelligence technologies have been widely used in computer vision, natural language processing, automatic driving, and other fields. However, artificial intelligence systems are vulnerable to adversarial attacks, which limit the applications of artificial intelligence (AI) technologies in key security fields. Recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This report aims to comprehensively summarize the latest research progress on adversarial attack and defense technologies in deep learning. It also includes an attack on a simple neural network. Then sort out the applications of adversarial attack technologies in computer vision, natural language processing, cyberspace security, and the physical world.    
