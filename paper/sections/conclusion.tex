\section{Conclusion}

    In this paper, a gradient-based adversarial image generation algorithm is proposed. Using the proposed algorithm, the adversary can generate adversarial images for target and non-target adversarial attacks. Neural networks are a black box, what a network learns is still unknown, which makes them more vulnerable to be duped. This paper demonstrated that tricking neural networks using adversarial examples is an easy task. Just like an ANN, all complex neural networks such as CNN are also susceptive to adversarial attacks. Instead of employing neural networks in every possible scenario, a tremendous amount of research is required to protect them from these attacks. 
    